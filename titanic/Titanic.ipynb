{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_data = pd.read_csv('./data/train.csv', index_col = 'PassengerId')\n",
    "raw_test_data = pd.read_csv('./data/test.csv', index_col = 'PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = raw_train_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_data = raw_test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name, Ticket, Cabin Feature는 큰 의미가 없을것이라 판단.<br>\n",
    "Column 삭제\n",
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "®삭제하려면 삭제할 수 있는 근거가 있어야 한다.<br>\n",
    "규칙이 없어 보여도 그 안에 무엇인가 있을 수 있음<br><br>\n",
    "\n",
    "여기서 근거를 찾아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | 삭제 이유                                                    |\n",
    "| -------- | ------------------------------------------------------------ |\n",
    "| Name     | *Mrs, Miss, Mr* 가 있으므로 성별과 혼인 여부 알 수 있음.<br> 1. 성별 => **Sex** Feature<br>  2. 혼인한 사람중에 배우자가 같이 동승한 경우 => **Sibsp** Feature<br> 3. 혼인했는데 배우자가 동승하지 않은 경우 => 큰 의미 없다고 판단 |\n",
    "| Ticket <br> Cabin   |  다 고유한 번호들로 느껴져서 안지울 수가 없음            |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null 있는지 확인\n",
    "'Age'에 177개 <br>\n",
    "'Embarked'에 2개 null확인됬음. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(train_data['Age'].isnull().sum())\n",
    "print(train_data['Embarked'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "Fare를 잘 보면 0 값들이 있다(총 15개).<br>\n",
    "이 사람들 무료로 탄걸까?<br>\n",
    "아마 아니겠지. <br>\n",
    "기록이 잘 안된거겠지. <br>\n",
    "이 친구들도 채워 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[train_data.Fare == 0]['Fare'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 히스토그램 그려서 분포를 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noJekxhn0ktQ4g16SGmfQS1Lj/heqruIAbw24BgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd215b4eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 100\n",
    "n, bins, patches = plt.hist(train_data['Fare'], num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right Skewed 이 경우에는 Median이 더 Mode에 가까움. <br>\n",
    "Median으로 채우자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_median=train_data.Fare.replace({0: train_data['Fare'].median()})\n",
    "(change_median==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Counts for Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived  Value Counts\n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "---------------------\n",
      "Pclass  Value Counts\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "---------------------\n",
      "Sex  Value Counts\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "---------------------\n",
      "Embarked  Value Counts\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "This Data has 2 null value\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "category_list = ['Survived', 'Pclass', 'Sex', 'Embarked']\n",
    "for i in category_list:\n",
    "    print(i,' Value Counts')\n",
    "    counts = train_data[i].value_counts()\n",
    "    print(counts)\n",
    "    if(counts.sum() != 891):\n",
    "        print('This Data has', 891-counts.sum() ,'null value')\n",
    "    print('---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편향된 데이터가 있는지 체크<br>\n",
    "잘 모르겠음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Pclass'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe for Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age       SibSp       Parch        Fare\n",
       "count  714.000000  891.000000  891.000000  891.000000\n",
       "mean    29.699118    0.523008    0.381594   32.204208\n",
       "std     14.526497    1.102743    0.806057   49.693429\n",
       "min      0.420000    0.000000    0.000000    0.000000\n",
       "25%     20.125000    0.000000    0.000000    7.910400\n",
       "50%     28.000000    0.000000    0.000000   14.454200\n",
       "75%     38.000000    1.000000    0.000000   31.000000\n",
       "max     80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[['Age', 'SibSp', 'Parch', 'Fare']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0xd21699fd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0xd218b4ba8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0xd21918320>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0xd219809b0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0xd219e1b38>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0xd219e1b70>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIgAAANeCAYAAAB57DV/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSJGnk/ge9tq4Rki4hzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd21603828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data.hist(bins=50, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.492143</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>-0.577147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.492143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091587</td>\n",
       "      <td>-0.061249</td>\n",
       "      <td>0.337932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.091587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.306895</td>\n",
       "      <td>0.171539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.018721</td>\n",
       "      <td>-0.061249</td>\n",
       "      <td>0.306895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>-0.577147</td>\n",
       "      <td>0.337932</td>\n",
       "      <td>0.171539</td>\n",
       "      <td>0.230046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pclass       Age     SibSp     Parch      Fare\n",
       "Pclass  1.000000 -0.492143  0.001087  0.018721 -0.577147\n",
       "Age    -0.492143  1.000000 -0.091587 -0.061249  0.337932\n",
       "SibSp   0.001087 -0.091587  1.000000  0.306895  0.171539\n",
       "Parch   0.018721 -0.061249  0.306895  1.000000  0.230046\n",
       "Fare   -0.577147  0.337932  0.171539  0.230046  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['Sex'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_1=train_data\n",
    "train_data_1['Sex']=train_data['Sex'].replace({'male':1 ,'female': 2})\n",
    "train_data_1['Embarked']=train_data_1['Embarked'].replace({'C': 1, 'Q':2, 'S':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.169718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.164681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>-0.110320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>-0.032565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.040449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.226311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.169718</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.226311</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Sex       Age     SibSp     Parch  \\\n",
       "Survived  1.000000 -0.338481  0.543351 -0.077221 -0.035322  0.081629   \n",
       "Pclass   -0.338481  1.000000 -0.131900 -0.369226  0.083081  0.018443   \n",
       "Sex       0.543351 -0.131900  1.000000 -0.093254  0.114631  0.245489   \n",
       "Age      -0.077221 -0.369226 -0.093254  1.000000 -0.308247 -0.189119   \n",
       "SibSp    -0.035322  0.083081  0.114631 -0.308247  1.000000  0.414838   \n",
       "Parch     0.081629  0.018443  0.245489 -0.189119  0.414838  1.000000   \n",
       "Fare      0.257307 -0.549500  0.182333  0.096067  0.159651  0.216225   \n",
       "Embarked -0.169718  0.164681 -0.110320 -0.032565  0.068900  0.040449   \n",
       "\n",
       "              Fare  Embarked  \n",
       "Survived  0.257307 -0.169718  \n",
       "Pclass   -0.549500  0.164681  \n",
       "Sex       0.182333 -0.110320  \n",
       "Age       0.096067 -0.032565  \n",
       "SibSp     0.159651  0.068900  \n",
       "Parch     0.216225  0.040449  \n",
       "Fare      1.000000 -0.226311  \n",
       "Embarked -0.226311  1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "Correlation은 Continuous Value를 전제로 한다.<br>\n",
    "Correlation을 계산해서 의미가 있으면 감을 잡을 순 있지만.<br>\n",
    "그것을 어떤 *'객관적 근거'*로서 활용하기 에는 무리가 있다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재<br>\n",
    "'Survived', 'Pclass', 'Sex', 'Embarked' -> Categorical <br>\n",
    "'Age', 'SibSp', 'Parch', 'Fare' -> Numerical But Discrete Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어쨋든 Correlation 이 Sex와 Pclass가 높긴 해."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "1. ***Correlation 은 Discrete일때도 객관적 근거가 될 수 없을까?***<br>\n",
    "2. ***그럼 뭐가 객관적 근거가 되는 걸까?***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1379</td>\n",
       "      <td>13919.17</td>\n",
       "      <td>248</td>\n",
       "      <td>136</td>\n",
       "      <td>14727.2865</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>233</td>\n",
       "      <td>678</td>\n",
       "      <td>7286.00</td>\n",
       "      <td>218</td>\n",
       "      <td>204</td>\n",
       "      <td>13966.6628</td>\n",
       "      <td>754.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass       Age  SibSp  Parch        Fare  Embarked\n",
       "Sex                                                                \n",
       "1         109    1379  13919.17    248    136  14727.2865    1500.0\n",
       "2         233     678   7286.00    218    204  13966.6628     754.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Sex').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "      <td>453</td>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>261</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Age  SibSp  Parch  Fare  Embarked\n",
       "Sex                                                     \n",
       "1         577     577  453    577    577   577       577\n",
       "2         314     314  261    314    314   314       312"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of non-null observations\n",
    "train_data.groupby('Sex').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight 1** \n",
    "여자는 대부분 살고 남자는 대부분 죽었음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    0.629630\n",
       "2    0.472826\n",
       "3    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Pclass').sum()['Survived'] / train_data.groupby('Pclass').count()['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight 2** \n",
    "1등석이 확실히 더 많이 살았음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "1.0    0.553571\n",
       "2.0    0.389610\n",
       "3.0    0.336957\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Embarked').sum()['Survived'] / train_data.groupby('Embarked').count()['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight 3** \n",
    "Cherbourg에서 승선한 사람은 50% 넘게 살았음 <br>\n",
    "출구 쪽에 있었나?<br>\n",
    "혹시 가장 마지막에 탑승했거나, 비상구에서 가까운 쪽에 위치하고 있었나?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SibSp\n",
      "0    0.345395\n",
      "1    0.535885\n",
      "2    0.464286\n",
      "3    0.250000\n",
      "4    0.166667\n",
      "5    0.000000\n",
      "8    0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Parch\n",
      "0    0.343658\n",
      "1    0.550847\n",
      "2    0.500000\n",
      "3    0.600000\n",
      "4    0.000000\n",
      "5    0.200000\n",
      "6    0.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.groupby('SibSp').sum()['Survived'] / train_data.groupby('SibSp').count()['Survived'])\n",
    "print(train_data.groupby('Parch').sum()['Survived'] / train_data.groupby('Parch').count()['Survived'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이건 딱히 얻을게 있는지 잘 모르겠다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>1.352413</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>2.535433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.792088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Sex         Age       SibSp       Parch  \\\n",
       "count  891.000000  891.000000  891.000000  714.000000  891.000000  891.000000   \n",
       "mean     0.383838    2.308642    1.352413   29.699118    0.523008    0.381594   \n",
       "std      0.486592    0.836071    0.477990   14.526497    1.102743    0.806057   \n",
       "min      0.000000    1.000000    1.000000    0.420000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000    1.000000   20.125000    0.000000    0.000000   \n",
       "50%      0.000000    3.000000    1.000000   28.000000    0.000000    0.000000   \n",
       "75%      1.000000    3.000000    2.000000   38.000000    1.000000    0.000000   \n",
       "max      1.000000    3.000000    2.000000   80.000000    8.000000    6.000000   \n",
       "\n",
       "             Fare    Embarked  \n",
       "count  891.000000  889.000000  \n",
       "mean    32.204208    2.535433  \n",
       "std     49.693429    0.792088  \n",
       "min      0.000000    1.000000  \n",
       "25%      7.910400    2.000000  \n",
       "50%     14.454200    3.000000  \n",
       "75%     31.000000    3.000000  \n",
       "max    512.329200    3.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [x for x in range(-1, 81, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "labels = [x for x in range(0, 8)]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "향후 New Features로 활용하게 편하게 <br>\n",
    "0~9세: 0, 10~19세 : 1 <br>\n",
    "이런식으로 세대 별로 매핑해서 Categorical Data로 만들었음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked  \\\n",
       "PassengerId                                                                  \n",
       "1                   0       3    1  22.0      1      0    7.2500       3.0   \n",
       "2                   1       1    2  38.0      1      0   71.2833       1.0   \n",
       "3                   1       3    2  26.0      0      0    7.9250       3.0   \n",
       "4                   1       1    2  35.0      1      0   53.1000       3.0   \n",
       "5                   0       3    1  35.0      0      0    8.0500       3.0   \n",
       "6                   0       3    1   NaN      0      0    8.4583       2.0   \n",
       "7                   0       1    1  54.0      0      0   51.8625       3.0   \n",
       "8                   0       3    1   2.0      3      1   21.0750       3.0   \n",
       "9                   1       3    2  27.0      0      2   11.1333       3.0   \n",
       "10                  1       2    2  14.0      1      0   30.0708       1.0   \n",
       "11                  1       3    2   4.0      1      1   16.7000       3.0   \n",
       "12                  1       1    2  58.0      0      0   26.5500       3.0   \n",
       "13                  0       3    1  20.0      0      0    8.0500       3.0   \n",
       "14                  0       3    1  39.0      1      5   31.2750       3.0   \n",
       "15                  0       3    2  14.0      0      0    7.8542       3.0   \n",
       "16                  1       2    2  55.0      0      0   16.0000       3.0   \n",
       "17                  0       3    1   2.0      4      1   29.1250       2.0   \n",
       "18                  1       2    1   NaN      0      0   13.0000       3.0   \n",
       "19                  0       3    2  31.0      1      0   18.0000       3.0   \n",
       "20                  1       3    2   NaN      0      0    7.2250       1.0   \n",
       "21                  0       2    1  35.0      0      0   26.0000       3.0   \n",
       "22                  1       2    1  34.0      0      0   13.0000       3.0   \n",
       "23                  1       3    2  15.0      0      0    8.0292       2.0   \n",
       "24                  1       1    1  28.0      0      0   35.5000       3.0   \n",
       "25                  0       3    2   8.0      3      1   21.0750       3.0   \n",
       "26                  1       3    2  38.0      1      5   31.3875       3.0   \n",
       "27                  0       3    1   NaN      0      0    7.2250       1.0   \n",
       "28                  0       1    1  19.0      3      2  263.0000       3.0   \n",
       "29                  1       3    2   NaN      0      0    7.8792       2.0   \n",
       "30                  0       3    1   NaN      0      0    7.8958       3.0   \n",
       "...               ...     ...  ...   ...    ...    ...       ...       ...   \n",
       "862                 0       2    1  21.0      1      0   11.5000       3.0   \n",
       "863                 1       1    2  48.0      0      0   25.9292       3.0   \n",
       "864                 0       3    2   NaN      8      2   69.5500       3.0   \n",
       "865                 0       2    1  24.0      0      0   13.0000       3.0   \n",
       "866                 1       2    2  42.0      0      0   13.0000       3.0   \n",
       "867                 1       2    2  27.0      1      0   13.8583       1.0   \n",
       "868                 0       1    1  31.0      0      0   50.4958       3.0   \n",
       "869                 0       3    1   NaN      0      0    9.5000       3.0   \n",
       "870                 1       3    1   4.0      1      1   11.1333       3.0   \n",
       "871                 0       3    1  26.0      0      0    7.8958       3.0   \n",
       "872                 1       1    2  47.0      1      1   52.5542       3.0   \n",
       "873                 0       1    1  33.0      0      0    5.0000       3.0   \n",
       "874                 0       3    1  47.0      0      0    9.0000       3.0   \n",
       "875                 1       2    2  28.0      1      0   24.0000       1.0   \n",
       "876                 1       3    2  15.0      0      0    7.2250       1.0   \n",
       "877                 0       3    1  20.0      0      0    9.8458       3.0   \n",
       "878                 0       3    1  19.0      0      0    7.8958       3.0   \n",
       "879                 0       3    1   NaN      0      0    7.8958       3.0   \n",
       "880                 1       1    2  56.0      0      1   83.1583       1.0   \n",
       "881                 1       2    2  25.0      0      1   26.0000       3.0   \n",
       "882                 0       3    1  33.0      0      0    7.8958       3.0   \n",
       "883                 0       3    2  22.0      0      0   10.5167       3.0   \n",
       "884                 0       2    1  28.0      0      0   10.5000       3.0   \n",
       "885                 0       3    1  25.0      0      0    7.0500       3.0   \n",
       "886                 0       3    2  39.0      0      5   29.1250       2.0   \n",
       "887                 0       2    1  27.0      0      0   13.0000       3.0   \n",
       "888                 1       1    2  19.0      0      0   30.0000       3.0   \n",
       "889                 0       3    2   NaN      1      2   23.4500       3.0   \n",
       "890                 1       1    1  26.0      0      0   30.0000       1.0   \n",
       "891                 0       3    1  32.0      0      0    7.7500       2.0   \n",
       "\n",
       "            Age_Cut  \n",
       "PassengerId          \n",
       "1               2.0  \n",
       "2               3.0  \n",
       "3               2.0  \n",
       "4               3.0  \n",
       "5               3.0  \n",
       "6               NaN  \n",
       "7               5.0  \n",
       "8               0.0  \n",
       "9               2.0  \n",
       "10              1.0  \n",
       "11              0.0  \n",
       "12              5.0  \n",
       "13              2.0  \n",
       "14              3.0  \n",
       "15              1.0  \n",
       "16              5.0  \n",
       "17              0.0  \n",
       "18              NaN  \n",
       "19              3.0  \n",
       "20              NaN  \n",
       "21              3.0  \n",
       "22              3.0  \n",
       "23              1.0  \n",
       "24              2.0  \n",
       "25              0.0  \n",
       "26              3.0  \n",
       "27              NaN  \n",
       "28              1.0  \n",
       "29              NaN  \n",
       "30              NaN  \n",
       "...             ...  \n",
       "862             2.0  \n",
       "863             4.0  \n",
       "864             NaN  \n",
       "865             2.0  \n",
       "866             4.0  \n",
       "867             2.0  \n",
       "868             3.0  \n",
       "869             NaN  \n",
       "870             0.0  \n",
       "871             2.0  \n",
       "872             4.0  \n",
       "873             3.0  \n",
       "874             4.0  \n",
       "875             2.0  \n",
       "876             1.0  \n",
       "877             2.0  \n",
       "878             1.0  \n",
       "879             NaN  \n",
       "880             5.0  \n",
       "881             2.0  \n",
       "882             3.0  \n",
       "883             2.0  \n",
       "884             2.0  \n",
       "885             2.0  \n",
       "886             3.0  \n",
       "887             2.0  \n",
       "888             1.0  \n",
       "889             NaN  \n",
       "890             2.0  \n",
       "891             3.0  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_ages = train_data.copy()\n",
    "train_data_with_ages['Age_Cut'] = pd.cut(train_data_with_ages['Age'], labels=labels,\n",
    "                              bins=bins, include_lowest = True)\n",
    "train_data_with_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut\n",
      "0    0.612903\n",
      "1    0.401961\n",
      "2    0.350000\n",
      "3    0.437126\n",
      "4    0.382022\n",
      "5    0.416667\n",
      "6    0.315789\n",
      "7    0.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_ages.groupby('Age_Cut').sum()['Survived'] / train_data_with_ages.groupby('Age_Cut').count()['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**나이대 별로 보면** 애기들이 확실히 더 많이 살았으니깐 <br>\n",
    "이 상태로 다시 Correlation 체크 하자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_cut = train_data_with_ages.Age_Cut.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_with_ages['Age_Cut']=int_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.169718</td>\n",
       "      <td>-0.080072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.349140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.090459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.980262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>-0.300555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.188898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.226311</td>\n",
       "      <td>0.090733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.169718</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.226311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Cut</th>\n",
       "      <td>-0.080072</td>\n",
       "      <td>-0.349140</td>\n",
       "      <td>-0.090459</td>\n",
       "      <td>0.980262</td>\n",
       "      <td>-0.300555</td>\n",
       "      <td>-0.188898</td>\n",
       "      <td>0.090733</td>\n",
       "      <td>-0.040965</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Sex       Age     SibSp     Parch  \\\n",
       "Survived  1.000000 -0.338481  0.543351 -0.077221 -0.035322  0.081629   \n",
       "Pclass   -0.338481  1.000000 -0.131900 -0.369226  0.083081  0.018443   \n",
       "Sex       0.543351 -0.131900  1.000000 -0.093254  0.114631  0.245489   \n",
       "Age      -0.077221 -0.369226 -0.093254  1.000000 -0.308247 -0.189119   \n",
       "SibSp    -0.035322  0.083081  0.114631 -0.308247  1.000000  0.414838   \n",
       "Parch     0.081629  0.018443  0.245489 -0.189119  0.414838  1.000000   \n",
       "Fare      0.257307 -0.549500  0.182333  0.096067  0.159651  0.216225   \n",
       "Embarked -0.169718  0.164681 -0.110320 -0.032565  0.068900  0.040449   \n",
       "Age_Cut  -0.080072 -0.349140 -0.090459  0.980262 -0.300555 -0.188898   \n",
       "\n",
       "              Fare  Embarked   Age_Cut  \n",
       "Survived  0.257307 -0.169718 -0.080072  \n",
       "Pclass   -0.549500  0.164681 -0.349140  \n",
       "Sex       0.182333 -0.110320 -0.090459  \n",
       "Age       0.096067 -0.032565  0.980262  \n",
       "SibSp     0.159651  0.068900 -0.300555  \n",
       "Parch     0.216225  0.040449 -0.188898  \n",
       "Fare      1.000000 -0.226311  0.090733  \n",
       "Embarked -0.226311  1.000000 -0.040965  \n",
       "Age_Cut   0.090733 -0.040965  1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_ages.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut\n",
      "0.0    0.612903\n",
      "1.0    0.401961\n",
      "2.0    0.350000\n",
      "3.0    0.437126\n",
      "4.0    0.382022\n",
      "5.0    0.416667\n",
      "6.0    0.315789\n",
      "7.0    0.000000\n",
      "Name: Survived, dtype: float64\n",
      "SibSp\n",
      "0    0.345395\n",
      "1    0.535885\n",
      "2    0.464286\n",
      "3    0.250000\n",
      "4    0.166667\n",
      "5    0.000000\n",
      "8    0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Parch\n",
      "0    0.343658\n",
      "1    0.550847\n",
      "2    0.500000\n",
      "3    0.600000\n",
      "4    0.000000\n",
      "5    0.200000\n",
      "6    0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Embarked\n",
      "1.0    0.553571\n",
      "2.0    0.389610\n",
      "3.0    0.336957\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_ages.groupby('Age_Cut').sum()['Survived'] / train_data_with_ages.groupby('Age_Cut').count()['Survived'])\n",
    "print(train_data_with_ages.groupby('SibSp').sum()['Survived'] / train_data_with_ages.groupby('SibSp').count()['Survived'])\n",
    "print(train_data_with_ages.groupby('Parch').sum()['Survived'] / train_data_with_ages.groupby('Parch').count()['Survived'])\n",
    "print(train_data_with_ages.groupby('Embarked').sum()['Survived'] / train_data_with_ages.groupby('Embarked').count()['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "확실히 Corrr값도 높게 나오는건, Pclass와 Sex<br>\n",
    "그러나 Corr이 객관적 근거가 될 수 없다는 것  <=> Corr 이외 에도 객관적으로 유의한 지표들이 있을 수 있다는 것 <br>\n",
    "Categorical데이터에 대해 추가적으로 찾아보면 <br>\n",
    "***Age_Cut : 어린애들 많이 살았고,***<br>\n",
    "***Embarked: 특정 위치에서 승선한 사람이 에서 더 많이 삼***<br>\n",
    "조금 있다가 묶어서 더 분석 해보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1차적으로 가장 중요한 Feature는 Sex, Pclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex  Pclass\n",
       "1    1         0.368852\n",
       "     2         0.157407\n",
       "     3         0.135447\n",
       "2    1         0.968085\n",
       "     2         0.921053\n",
       "     3         0.500000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Sex', 'Pclass']).sum()['Survived'] / train_data.groupby(['Sex', 'Pclass']).count()['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Sex\n",
       "1       1      0.368852\n",
       "        2      0.968085\n",
       "2       1      0.157407\n",
       "        2      0.921053\n",
       "3       1      0.135447\n",
       "        2      0.500000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Pclass', 'Sex']).sum()['Survived'] / train_data.groupby(['Pclass', 'Sex']).count()['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 여자가 Sex 2번, <br>\n",
    "***여자 + 1등석 96.8% 생존***<br>\n",
    "***여자 + 2등석 92.1% 생존***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pclass_sex = train_data.groupby(['Pclass', 'Sex']).sum()['Survived'] / train_data.groupby(['Pclass', 'Sex']).count()['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_groups = 3\n",
    "women_survived = []\n",
    "men_survived= []\n",
    "for i in range(1, 4):\n",
    "    men_survived.append(pclass_sex[i][1])\n",
    "    women_survived.append(pclass_sex[i][2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYFdWZ7/HvjxZFI2AQYpSLgMELAdQEUNEo0USUJDKa\nm2B04iUeHB3vt+TEaMY4ycQ4x7uMUQ8xKmCCUSScUZNgNAIKKIiIZlCRi0YBb4BX5D1/1GrcNN3s\nDXR116Z/n+fpp7uq1l717l2791tr1dqrFBGYmZkVTavmDsDMzKw+TlBmZlZITlBmZlZITlBmZlZI\nTlBmZlZITlBmZlZITlDW5CSNknRJDvVeJumOxq53c0haIOkrzR3H5pA0WNLiDWwPSZ9rypgaiKPq\nX2tblxOUASDpIElTJL0t6Q1Jj0kakMe+ImJkRFyeR90NSR+yayStlLRC0vOSTmzKGJqLpNGSftbc\ncZQj6fuSPk7H6B1JsyR9vWR7O0lXS1qYyryQljs2Z9yWHycoQ1I7YCJwHdAB6Az8FPhgE+qSpKK+\nr16JiO2BdsBFwK8l9W7mmHIlqaa5Y9hIU9Mx2gG4Fbhb0qclbQ38Gfg8cATZMTwAWAYMbK5gLV9F\n/SCxprU7QESMiYiPI+K9iHgwIp6G9bvOJHVP3TpbpeWHJV0h6THgXeACSTNKdyDpHEkT0t9rz+gl\nzatzlryVpKWSvpCW908tu7ckzZY0uKRsD0l/TS2ih4CKzqQjcy/wJtC7gv3sImlCalnOl/SDkm2X\nSfq9pHEpjicl7V3ffiW1knRxOvNfLuluSR0aKNtR0sQUzxuSHq1N/JL2Sq/5W5LmSjqq5HGjJd0k\naZKkVcDJwHHAhanVcX/JcxqfXuuXJJ1ZUse2qZ43JT0LVNKSHirpRUnLJF2ZnuvWKfa+JXV/RtK7\nkjptqLKIWAPcBmwL7AacAHQDjo6IZyNiTUS8HhE/i4hJ9bx+AyVNTa/Rq5KuT0mu9iTq/0h6PbXU\n5kjqk7YNlfRsOpZLJJ1fwXO3nDhBGcDfgY8l/UbSkZI+vQl1HA+cCrQFRgF7SOpVsn0EcFc9jxsD\nDC9ZHgIsi4gnJXUG/gj8jKxldz4wvuTD7S5gJlliuhz450oCTR+eR5Odpc+pYD9jgcXALsC3gH+X\ndGhJlcOA36XH3gXcK6l1Pbv+V+CfgENSXW8CNzQQ5nlpn52AnYAfAZHqvR94EPhMqvNOSXuUPHYE\ncAXZsbgduBP4ZURsHxHfSInufmA2WWv5MOBsSUPS4y8lSwq7kR2PSl7Xo4H+wBfS63FSRHxI9tp9\nr6TccODPEbF0Q5Wlk59TgJXA/wBfAf47IlZWEAvAx8A5ZO+NA8ie47+kbYcDB5OdmLUHvgMsT9tu\nBf5XRLQF+gB/qXB/lgMnKCMi3gEOAgL4NbA0tRh22ohqRkfE3IhYHRFvA/eREk9KVHsCE+p53F3A\nUZK2S8sjyJIWZB9skyJiUjpjfgiYQXa23o3szP6SiPggIh4h+9DdkF0kvUXWLXQpcHxEPF9mP12B\nA4GLIuL9iJgF3EJ2Rl9rZkT8PiI+Av4TaAPsX8/+RwL/OyIWR8QHwGXAt2pbonV8BOwM7BoRH0XE\no5FNnLk/sD3wi4j4MCL+QtY9W5rk74uIx9Jzeb+eugcAnSLi31IdL5Id92PT9u8AV0TEGxGxCLi2\n4Zd0rf9I5RcCV5fE8xtguCSl5eOB326gnv3TMfpHquPo9H7aEXi1gjgAiIiZETEtvR8XAP9FdmIA\n2Wvbluw9qYiYFxGvlmzrLaldRLwZEU9Wuk9rfE5QBkD6J/1+RHQhO3PcheyDplKL6izfxScfUiOA\neyPi3Xr2Ox+YB3wjJamj+KSltSvw7dRN81b64DqI7IN7F+DNiFhVUt3LZWJ8JSJ2iIgOEbFPRIyt\ncD9vRMSKOvvpXN9zT11Tta2tunYF/lCyj3lkZ/r1nQhcCcwHHkxdZxen9bsAi9J+ysbTgF1Jybok\nlh+VxLFLnTrKva519/lyqoOIeJys23ewpD2Bz1H/iUqtaekYdYyI/SPiT2n9crLjURFJu6cu0n9I\negf4d1IXcErq15O1Xl+XdLOy67AA3wSGAi8r6z4+oNJ9WuNzgrL1RMRzwGiyRAWwCtiupMhn63tY\nneWHgE6S9iFLVPV179Wq7eYbBjybkhZkH3q/TR9YtT+fiohfkJ1Nf1rSp0rq6Vb+2dVrQ/t5Begg\nqW2d/SwpWe5a+0fqPuuSHlfffo6ss582EbGkbsGIWBER50VET7Kkfa6kw1K9XbXuQJS68dQ9FnWX\nFwEv1YmjbUQMTdtfLX1OVPa61i1f+vx/Q9ZKPR74fQOtunL+BAypc7w35CbgOaBXRLQjS8C1rTgi\n4tqI+CLZNcjdgQvS+ukRMYys+/Re4O5NiNUaiROUIWlPSedJ6pKWu5IljGmpyCzgYEndJLUHfliu\nztTd9TuylkAHsoTVkLFk1wVOY91EdgdZy2qIpBpJbZQNF+8SES+TdcP9NF2MPwj4xsY87wr3swiY\nAvw8re9HNvCg9PtWX5R0TOqqO5ts9OO09faSXZu7QtKuAJI6SRpWX0CSvi7pc6lr7G2yltYaoLZF\ncqGk1soGc3yD7DVsyGtAz5LlJ4AVki5SNiCiRlIfffK1gruBHyobPdeF7DpXORek8l2Bs4BxJdvu\nILtG9T2ya2Kb4rdkiXV8er+2krSjpB9JGlpP+bbAO8DK1HI7rXaDpAGS9kvX81YB7wNr0vvoOEnt\n0/v3HbLX3JqJE5QBrAD2Ax5XNvJrGvAM2YV60jWZccDTZIMSJlZY711kF7d/FxGrGyqU+v+nAoMo\n+WBLyWEY2dnvUrIPqAv45H07IsX9Btk1pU368KtgP8OB7mStgj8Al5Z0PUF2ve27ZIMejgeOSR9w\ndV1D1r31oKQVZK/zfg2E1Yus1bCS7LW5MSImp4EH3wCOJLuWdiNwQmr1NuRWsusqb0m6NyI+Br4O\n7AO8lOq5hWzAAGRfMXg5bXuQDV8zqnUf2XtjFtmAk1trN6TX90myltyjFdS1nnTN7itkraKHyJLH\nE2Tddo/X85Dzyd4fK8iur5UmzHZp3Ztkz3M52YkUZMdvQeoWHEk2AtKaicI3LDTbZJIuAz4XEd8r\nV7Ylk3Qb2TXAHzd3LFY96hs9ZGbWaCR1B44B9m3eSKzauIvPzHIj6XKy7uIrI+Kl5o7Hqou7+MzM\nrJDcgjIzs0KqumtQHTt2jO7duzd3GGZmtolmzpy5LCI2OB8j5Jig0qidrwOvR0SferaLbNjtULLv\ndXy/kmlFunfvzowZM8oVMzOzgpJUyewkuXbxjSabFr8hR5J916MX2SSjN+UYi5mZVZncElSavPON\nDRQZBtwemWnADpIqnmvLzMy2bM05SKIz604wuZh1J7xcS9KpkmZImrF06QZn6Tczsy1EVQySiIib\ngZsB+vfv73HxZtbsPvroIxYvXsz772/K3LctQ5s2bejSpQutW9d3e7TymjNBLWHdGZC7sO6MzGZm\nhbV48WLatm1L9+7d+eR2V1YrIli+fDmLFy+mR48em1RHc3bxTQBOUGZ/4O2Sm4aZmRXa+++/z447\n7ujk1ABJ7LjjjpvVwsxzmPkYYDDQUdJistmmWwNExChgEtkQ8/lkw8xPzCsWM7M8ODlt2Oa+Prkl\nqIgYXmZ7AKfntX8zM6tuVTFIwsys6E4ePb1R67v1+wPKlpHEcccdxx13ZPfPXL16NTvvvDP77bcf\nEydWetu24nKCqgZ3fbe5I6jciHHly5hZo/jUpz7FM888w3vvvce2227LQw89ROfO9X5bpyp5slgz\nsyo2dOhQ/vjHPwIwZswYhg//5OrKqlWrOOmkkxg4cCD77rsv9913HwCjR4/mmGOO4YgjjqBXr15c\neOGFzRJ7OU5QZmZV7Nhjj2Xs2LG8//77PP300+y3335rt11xxRUceuihPPHEE0yePJkLLriAVatW\nATBr1izGjRvHnDlzGDduHIsWLWpoF83GXXxmZlWsX79+LFiwgDFjxjB06NB1tj344INMmDCBX/3q\nV0A2NH7hwoUAHHbYYbRv3x6A3r178/LLL9O1a1eKxAnKzKzKHXXUUZx//vk8/PDDLF++fO36iGD8\n+PHsscce65R//PHH2WabbdYu19TUsHr16iaLt1Lu4jMzq3InnXQSl156KX379l1n/ZAhQ7juuuuo\nvXP6U0891RzhbTK3oMzMGkElw8Lz0qVLF84888z11l9yySWcffbZ9OvXjzVr1tCjR4+qGn6u2sxa\nLfr37x8t7oaFHmZuVjjz5s1jr732au4wCq++10nSzIjoX+6x7uIzM7NCcoIyM7NC8jUos6Kppi5d\ncLeu5cYtKDMzKyQnKDMzKyQnKDMzKyRfgzIzawyNfe2wzLW9c845h1133ZWzzz4byL6U27VrV265\n5RYAzjvvPDp37sy5557buHE1IbegzMyq0IEHHsiUKVMAWLNmDcuWLWPu3Llrt0+ZMoVBgwY1V3iN\nwgnKzKwKDRo0iKlTpwIwd+5c+vTpQ9u2bXnzzTf54IMPmDdvHvvuuy8XXHABffr0oW/fvowbl7XK\nHn74YQ455BCGDRtGz549ufjii7nzzjsZOHAgffv25YUXXgBg6dKlfPOb32TAgAEMGDCAxx57DIDL\nLruMk046icGDB9OzZ0+uvfbaXJ6ju/jMzKrQLrvswlZbbcXChQuZMmUKBxxwAEuWLGHq1Km0b9+e\nvn37MnHiRGbNmsXs2bNZtmwZAwYM4OCDDwZg9uzZzJs3jw4dOtCzZ09OOeUUnnjiCa655hquu+46\nrr76as466yzOOeccDjroIBYuXMiQIUOYN28eAM899xyTJ09mxYoV7LHHHpx22mm0bt26UZ+jE5SZ\nWZUaNGgQU6ZMYcqUKZx77rksWbKEKVOm0L59ew488ED+9re/MXz4cGpqathpp5045JBDmD59Ou3a\ntWPAgAHsvPPOAOy2224cfvjhAPTt25fJkycD8Kc//Ylnn3127f7eeecdVq5cCcDXvvY1ttlmG7bZ\nZhs+85nP8Nprr9GlS5dGfX5OUGZmVar2OtScOXPo06cPXbt25aqrrqJdu3aceOKJaxNNfUpvt9Gq\nVau1y61atVp76401a9Ywbdo02rRps8HH53W7Dl+DMjOrUoMGDWLixIl06NCBmpoaOnTowFtvvcXU\nqVMZNGgQX/rSlxg3bhwff/wxS5cu5ZFHHmHgwIEV13/44Ydz3XXXrV2eNWtWHk+jQW5BmZk1hmaY\n8qlv374sW7aMESNGrLNu5cqVdOzYkaOPPpqpU6ey9957I4lf/vKXfPazn+W5556rqP5rr72W008/\nnX79+rF69WoOPvhgRo0aldfTWY9vt1ENqmluNs/Ltvmq6XhDiz3mvt1GZXy7DTMz2+I4QZmZWSE5\nQZmZbaJqu0TS1Db39XGCMjPbBG3atGH58uVOUg2ICJYvX17vEPVKeRSfmdkm6NKlC4sXL2bp0qXN\nHUphtWnTZrO+vOsEZWa2CVq3bk2PHj2aO4wtmrv4zMyskJygzMyskJygzMyskJygzMyskHJNUJKO\nkPS8pPmSLq5ne3tJ90uaLWmupBPzjMfMzKpHbglKUg1wA3Ak0BsYLql3nWKnA89GxN7AYOAqSVvn\nFZOZmVWPPFtQA4H5EfFiRHwIjAWG1SkTQFtJArYH3gAa/6YiZmZWdfJMUJ2BRSXLi9O6UtcDewGv\nAHOAsyJiTd2KJJ0qaYakGf5SnJlZy9DcgySGALOAXYB9gOsltatbKCJujoj+EdG/U6dOTR2jmZk1\ngzwT1BKga8lyl7Su1InAPZGZD7wE7JljTGZmViXyTFDTgV6SeqSBD8cCE+qUWQgcBiBpJ2AP4MUc\nYzIzsyqR21x8EbFa0hnAA0ANcFtEzJU0Mm0fBVwOjJY0BxBwUUQsyysmMzOrHrlOFhsRk4BJddaN\nKvn7FeDwPGMwM7Pq1NyDJMzMzOrlBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXk\nBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVm\nZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXk\nBGVmZoXkBGVmZoXkBGVmZoW0VaUFJX0a2AV4D1gQEWtyi8rMzFq8DSYoSe2B04HhwNbAUqANsJOk\nacCNETE59yjNzKzFKdeC+j1wO/CliHirdIOkLwLHS+oZEbfmFaCZmbVMG0xQEfHVDWybCcxs9IjM\nzMzYiGtQAJI6AWcB2wKjIuJ/conKzMxavI0dxXcV8ADwB+CucoUlHSHpeUnzJV3cQJnBkmZJmivp\nrxsZj5mZbaE2mKAkPSDp4JJVWwML0s82ZR5bA9wAHAn0BoZL6l2nzA7AjcBREfF54NsbGb+ZmW2h\nyrWgvgN8Q9IYSbsBlwA/B64B/qXMYwcC8yPixYj4EBgLDKtTZgRwT0QsBIiI1zf2CZiZ2Zap3CCJ\nt4ELJPUErgBeAc6oO6KvAZ2BRSXLi4H96pTZHWgt6WGgLXBNRNxetyJJpwKnAnTr1q2CXZuZWbUr\n9z2o3YDTgA+B84DdgHGS/gjcEBEfN8L+vwgcRjbwYqqkaRHx99JCEXEzcDNA//79YzP3aWZmVaBc\nF98Y4B5gMvDbiHg0IoYAbwEPlnnsEqBryXKXtK7UYuCBiFgVEcuAR4C9Kw3ezMy2XOUS1DbAS2SD\nIrarXZm64b5e5rHTgV6SekjaGjgWmFCnzH3AQZK2krQdWRfgvMrDNzOzLVW570H9C3A9WRffyNIN\nEfHehh4YEaslnUE2LL0GuC0i5koambaPioh5kv4beBpYA9wSEc9s2lMxM7MtSblBEo8Bj21q5REx\nCZhUZ92oOstXAldu6j7MzGzLVO57UPdL+rqk1vVs6ynp3ySdlF94ZmbWUpXr4vsBcC5wjaQ3+GQ2\n8+7AC8D1EXFfrhGamVmLVK6L7x/AhcCFkroDO5PdD+rvEfFu7tGZmVmLVfFksRGxgGw0n5mZWe7K\nfVF3BdDgF2Mjol2jR2RmZkb5Lr62AJIuB14FfgsIOI6su8/MzCwXld5u46iIuDEiVkTEOxFxE+tP\n/GpmZtZoKk1QqyQdJ6lGUitJxwGr8gzMzMxatkoT1AiyW2+8ln6+ndaZmZnloqJRfGkEn7v0zMys\nyVTUgpK0u6Q/S3omLfeT9ON8QzMzs5as0i6+XwM/BD4CiIinyWYnNzMzy0WlCWq7iHiizrrVjR2M\nmZlZrUoT1LJ0d90AkPQtsu9FmZmZ5aLSqY5OJ7vl+p6SlpDdxPC43KIyM7MWr9IE9XJEfEXSp4BW\nEbEiz6DMzMwqTVAvpTvfjgP+kmM8ZmYtz13fbe4IKjdiXJPtqtJrUHsCfyLr6ntJ0vWSDsovLDMz\na+kqSlAR8W5E3B0RxwD7Au2Av+YamZmZtWiVtqCQdIikG4GZZHfV/U5uUZmZWYtX0TUoSQuAp4C7\ngQsiwhPFmplZriodJNEvIt7JNRIzM7MS5e6oe2FE/BK4QtJ6d9aNiDNzi8zMzFq0ci2oeen3jLwD\nMTMzK1Xulu/3pz/nRMSTTRCPmZkZUPkovqskzZN0uaQ+uUZkZmZG5d+D+jLwZWAp8F+S5vh+UGZm\nlqeKvwcVEf+IiGuBkcAs4Ce5RWVmZi1epXfU3UvSZZLmANcBU4AuuUZmZmYtWqXfg7oNGAsMiYhX\ncozHzMwMqCBBSaoBXoqIa5ogHjMzM6CCLr6I+BjoKmnrJojHzMwM2Ij7QQGPSZoArJ2HLyL+M5eo\nzMysxas0Qb2QfloBbfMLx8zMLFNRgoqIn25K5ZKOAK4BaoBbIuIXDZQbAEwFjo2I32/KvszMbMtS\n6e02JgP1TRZ76AYeUwPcAHwVWAxMlzQhIp6tp9x/AA9uRNxmZraFq7SL7/ySv9sA3wRWl3nMQGB+\nRLwIIGksMAx4tk65fwXGAwMqjMXMzFqASrv4ZtZZ9ZikJ8o8rDOwqGR5MbBfaQFJnYGjyaZRajBB\nSToVOBWgW7dulYRsZmZVrtKZJDqU/HRM15baN8L+rwYuiog1GyoUETdHRP+I6N+pU6dG2K2ZmRVd\npV18M/nkGtRqYAFwcpnHLAG6lix3SetK9QfGSgLoCAyVtDoi7q0wLjMz20KVu6PuAGBRRPRIy/9M\ndv1pAetfS6prOtBLUg+yxHQsMKK0QG29qe7RwEQnJzMzg/JdfP8FfAgg6WDg58BvgLeBmzf0wIhY\nDZwBPEB2Z967I2KupJGSRm5u4GZmtmUr18VXExFvpL+/C9wcEeOB8ZJmlas8IiYBk+qsG9VA2e+X\nD9fMzFqKci2oGkm1Seww4C8l2yq9fmVmZrbRyiWZMcBfJS0D3gMeBZD0ObJuvqp08ujpzR3CRrnV\n0/SaWQu0wQQVEVdI+jOwM/BgRNSO5GtF9gVbMzOzXJTtpouIafWs+3s+4ZiZmWUq+qKumZlZU3OC\nMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOz\nQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKC\nMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOz\nQso1QUk6QtLzkuZLurie7cdJelrSHElTJO2dZzxmZlY9cktQkmqAG4Ajgd7AcEm96xR7CTgkIvoC\nlwM35xWPmZlVlzxbUAOB+RHxYkR8CIwFhpUWiIgpEfFmWpwGdMkxHjMzqyJ5JqjOwKKS5cVpXUNO\nBv5fjvGYmVkV2aq5AwCQ9GWyBHVQA9tPBU4F6NatWxNGZmZmzSXPFtQSoGvJcpe0bh2S+gG3AMMi\nYnl9FUXEzRHRPyL6d+rUKZdgzcysWPJMUNOBXpJ6SNoaOBaYUFpAUjfgHuD4iPh7jrGYmVmVya2L\nLyJWSzoDeACoAW6LiLmSRqbto4CfADsCN0oCWB0R/fOKyczMqkeu16AiYhIwqc66USV/nwKckmcM\nZmZWnTyThJmZFZITlJmZFZITlJmZFZITlJmZFVIhvqhrlreTR09v7hAqduvWzR2BWTG4BWVmZoXk\nBGVmZoXkBGVmZoXkBGVmZoXkQRJmtsWppkEx4IExDXELyszMCskJyszMCskJyszMCskJyszMCskJ\nyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszM\nCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJ\nyszMCskJyszMCinXBCXpCEnPS5ov6eJ6tkvStWn705K+kGc8ZmZWPXJLUJJqgBuAI4HewHBJvesU\nOxLolX5OBW7KKx4zM6suebagBgLzI+LFiPgQGAsMq1NmGHB7ZKYBO0jaOceYzMysSigi8qlY+hZw\nRESckpaPB/aLiDNKykwEfhERf0vLfwYuiogZdeo6layFBbAH8HwuQbcsHYFlzR2ENSkf85alyMd7\n14joVK7QVk0RyeaKiJuBm5s7ji2JpBkR0b+547Cm42PesmwJxzvPLr4lQNeS5S5p3caWMTOzFijP\nBDUd6CWph6StgWOBCXXKTABOSKP59gfejohXc4zJzMyqRG5dfBGxWtIZwANADXBbRMyVNDJtHwVM\nAoYC84F3gRPzisfW4y7TlsfHvGWp+uOd2yAJMzOzzeGZJMzMrJCcoMzMrJCcoKqApNskvS7pmQrK\nDpY0aAPbj5Q0Q9Kzkp6SdFVaf5mk8xszbts4krpKmpyOzVxJZ21CHQ9LWm9osaTWkn4h6X8kPSlp\nqqQj07YFkjo2xnOwjSOpjaQnJM1Ox/ynG/HYlQ2s/6yksZJekDRT0iRJu0vqXslnSJE4QVWH0cAR\nFZYdDNSboCT1Aa4HvhcRvYH+ZANUrBhWA+elY7M/cHo904NtqsuBnYE+EfEF4J+Ato1Ut226D4BD\nI2JvYB/giDSieR2SKhrQJknAH4CHI2K3iPgi8ENgp0aMuck4QVWBiHgEeKPueklnprPtp9MZU3dg\nJHCOpFmSvlTnIRcCV0TEc6nejyNivfkPJf1A0vR0Vjde0nZp/bclPZPWP5LWfT6dAc5KcfRq1Cff\ngkTEqxHxZPp7BTAP6AxrW0b/kV7rv9ceW0nbpmM/T9IfgG3r1puO3w+Af42ID1L9r0XE3fWUvTed\ndc9NM7ggqUbS6HTs50g6J61f5/2Xy4uyhUvTvNW2hFqnn4C1x/xqSTOAs9JXdqamY/CzBqr8MvBR\nGiVdu4/ZEfFoaaHUmno0taafrO11kbSzpEfS//Mzkr7U0PFvClUxk4Q16GKgR0R8IGmHiHhL0ihg\nZUT8qp7yfYCrKqj3noj4NUD6RzgZuA74CTAkIpZI2iGVHQlcExF3pu+71Wzuk7LsAwTYF3i8ZPVW\nETFQ0lDgUuArwGnAuxGxl6R+wJP1VPc5YGFEvFPBrk+KiDckbQtMlzQe6A50jog+KbbaY7/O+2+j\nn6QBayfWnkl2nG6IiNJjvnXtbBCSJgA3RcTtkk5voLo+qa5yXge+GhHvp5PKMWQ9KiOAByLiihTX\ndmQtu/qOf+7cgqpuTwN3SvoeWfdQY+mTzq7mAMcBn0/rHwNGS/oBnySiqcCPJF1ENr/We40YR4sk\naXtgPHB2naRyT/o9kyxpABwM3AEQEU+TvSc2x5mSZgPTyGZ56QW8CPSUdJ2kI4DamPJ6/7UoqSdj\nH7KZdAamrvha40r+PpAskQD8djN32xr4dfof/x3ZHScgm2DhREmXAX1TS76h4587J6jq9jWyW5p8\ngexst1yLeC7wxQrqHQ2cERF9gZ8CbQAiYiTwY7IPrpmSdoyIu4CjgPeASZIO3ZQnYhlJrcmS050R\ncU+dzR+iF0CLAAADF0lEQVSk3x+zcb0f84FuktqV2fdgslbZAemayFNAm4h4E9gbeJisxXxLesjG\nvv9sAyLiLWAy615vXlW3WJlqKv0fPwd4jey49ge2TjE8QnbSs4TsZPSEDRz/3DlBVSlJrYCuETEZ\nuAhoD2wPrKDhi99XkrV2dq+tQ2lmjzraAq+mD8vjSva5W0Q8HhE/AZYCXSX1BF6MiGuB+4B+jfMM\nW550gftWYF5E/GeFD3uErFumdhDMeq9/RLyb6r0mdcMiqZOkb9cp2h54MyLelbQn2UANlI3waxUR\n48lOUL6wgfefbYR0HHZIf28LfBV4roHij5FNGQcl/5d1/AXYpvb6Yaq3Xz3Xo9sDr0bEGuB4Uo+I\npF2B11IX/y1kx3q947+RT3OTOUFVAUljyLrS9pC0WNLJZG+oO1IT/Sng2nQGdj9wtOoZJJG6gM4G\nxkiaBzwD9Kxnl5eQXft4jHX/Wa5MF0mfAaYAs4HvAM9ImkXW/317oz3xludAsg+LQ9Pxm5WuN23I\nTcD26Xj+Gw1ff/gx2UnFs+n4TWT9rpr/BrZKdf2CrJsPsoEaD6djfAfZqLCG3n+2cXYGJkt6mqx7\n7aGImNhA2bPIRnbOIQ2eqSuyqYGOBr6ibJj5XODnwD/qFL0R+OfUnbsnn7TUBgOzJT0FfBe4hvqP\nf5PwVEdmZlZIbkGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZ5UwNzy5dVTNLmzU1f/Pb\nLEfpy7d/AH4TEcemdXtTpbNLmzUlt6DM8lXv7NLAotrlaplZ2qypuQVllq9KZpeuipmlzZqaE5RZ\n82sNXC9pH7KJYHdP66cDt6U5Ee+NiFmS1s4sDfwReLBZIjZrAu7iM8tXJbNLV8XM0mZNzQnKLF/1\nzi5NdsuSWlUxs7RZU3MXn1mOIiIkHQ1cnW7q+D6wgGxW+Vo3AuMlnUA2o3jpzNIXSPoIWAmcQDaz\n9P9Nt7uAJpxZ2qypeTZzMzMrJHfxmZlZITlBmZlZITlBmZlZITlBmZlZITlBmZlZITlBmZlZITlB\nmZlZIf1/PV1KW7BihmcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd226d24e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.7\n",
    " \n",
    "rects1 = plt.bar(index, men_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='Men')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, women_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='Women')\n",
    " \n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Survived(%)')\n",
    "plt.title('Survived People sorted by PClass')\n",
    "plt.xticks(index + bar_width, ('1st Class', '2nd Class', '3rd Class'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sex_pclass= train_data.groupby(['Sex', 'Pclass']).sum()['Survived'] / train_data.groupby(['Sex', 'Pclass']).count()['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex  Pclass\n",
       "1    1         0.368852\n",
       "     2         0.157407\n",
       "     3         0.135447\n",
       "2    1         0.968085\n",
       "     2         0.921053\n",
       "     3         0.500000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sex_list = ['male', 'female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_groups = 2\n",
    "first_survived = []\n",
    "second_survived= []\n",
    "third_survived =[]\n",
    "for i in [1, 2]:\n",
    "    first_survived.append(sex_pclass[i][1])\n",
    "    second_survived.append(sex_pclass[i][2])\n",
    "    third_survived.append(sex_pclass[i][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noMzMLJMcUGZmlkn/H9zpx1SiKXeZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd2288c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.15\n",
    "opacity = 0.7\n",
    " \n",
    "rects1 = plt.bar(index, first_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='1st Survived')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, second_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='2nd Survived')\n",
    "rects3 = plt.bar(index + bar_width+bar_width, third_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='3rd Survived')\n",
    "\n",
    " \n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Survived')\n",
    "plt.title('Survived People sorted by Sex')\n",
    "plt.xticks(index + bar_width, ('Men', 'Women'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 새로운 Feature 만들어 보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 Pclass와 Sex를 기본으로<br>\n",
    "아까 의심이 됬던 Age와 더불어 여러가지를 상상력으로 조합해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_with_new_features = train_data_with_ages.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.169718</td>\n",
       "      <td>-0.080072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.349140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.090459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.980262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>-0.300555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.188898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.226311</td>\n",
       "      <td>0.090733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.169718</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.226311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Cut</th>\n",
       "      <td>-0.080072</td>\n",
       "      <td>-0.349140</td>\n",
       "      <td>-0.090459</td>\n",
       "      <td>0.980262</td>\n",
       "      <td>-0.300555</td>\n",
       "      <td>-0.188898</td>\n",
       "      <td>0.090733</td>\n",
       "      <td>-0.040965</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Sex       Age     SibSp     Parch  \\\n",
       "Survived  1.000000 -0.338481  0.543351 -0.077221 -0.035322  0.081629   \n",
       "Pclass   -0.338481  1.000000 -0.131900 -0.369226  0.083081  0.018443   \n",
       "Sex       0.543351 -0.131900  1.000000 -0.093254  0.114631  0.245489   \n",
       "Age      -0.077221 -0.369226 -0.093254  1.000000 -0.308247 -0.189119   \n",
       "SibSp    -0.035322  0.083081  0.114631 -0.308247  1.000000  0.414838   \n",
       "Parch     0.081629  0.018443  0.245489 -0.189119  0.414838  1.000000   \n",
       "Fare      0.257307 -0.549500  0.182333  0.096067  0.159651  0.216225   \n",
       "Embarked -0.169718  0.164681 -0.110320 -0.032565  0.068900  0.040449   \n",
       "Age_Cut  -0.080072 -0.349140 -0.090459  0.980262 -0.300555 -0.188898   \n",
       "\n",
       "              Fare  Embarked   Age_Cut  \n",
       "Survived  0.257307 -0.169718 -0.080072  \n",
       "Pclass   -0.549500  0.164681 -0.349140  \n",
       "Sex       0.182333 -0.110320 -0.090459  \n",
       "Age       0.096067 -0.032565  0.980262  \n",
       "SibSp     0.159651  0.068900 -0.300555  \n",
       "Parch     0.216225  0.040449 -0.188898  \n",
       "Fare      1.000000 -0.226311  0.090733  \n",
       "Embarked -0.226311  1.000000 -0.040965  \n",
       "Age_Cut   0.090733 -0.040965  1.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_ages.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex  SibSp\n",
      "1    0         73\n",
      "     1         32\n",
      "     2          3\n",
      "     3          0\n",
      "     4          1\n",
      "     5          0\n",
      "     8          0\n",
      "2    0        137\n",
      "     1         80\n",
      "     2         10\n",
      "     3          4\n",
      "     4          2\n",
      "     5          0\n",
      "     8          0\n",
      "Name: Survived, dtype: int64\n",
      "Sex  SibSp\n",
      "1    0        434\n",
      "     1        103\n",
      "     2         15\n",
      "     3          5\n",
      "     4         12\n",
      "     5          4\n",
      "     8          4\n",
      "2    0        174\n",
      "     1        106\n",
      "     2         13\n",
      "     3         11\n",
      "     4          6\n",
      "     5          1\n",
      "     8          3\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_new_features.groupby(['Sex','SibSp']).sum()['Survived'])\n",
    "print(train_data_with_new_features.groupby(['Sex','SibSp']).count()['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut  Parch\n",
      "0.0      0          1\n",
      "         1         35\n",
      "         2         26\n",
      "1.0      0         71\n",
      "         1         15\n",
      "         2         15\n",
      "         3          1\n",
      "2.0      0        187\n",
      "         1         15\n",
      "         2         15\n",
      "         3          2\n",
      "         4          1\n",
      "3.0      0        136\n",
      "         1         19\n",
      "         2          8\n",
      "         5          4\n",
      "4.0      0         67\n",
      "         1         14\n",
      "         2          3\n",
      "         3          1\n",
      "         4          2\n",
      "         5          1\n",
      "         6          1\n",
      "5.0      0         38\n",
      "         1          8\n",
      "         2          1\n",
      "         3          1\n",
      "6.0      0         15\n",
      "         1          3\n",
      "         4          1\n",
      "7.0      0          5\n",
      "         1          1\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_new_features.groupby(['Age_Cut', 'Parch']).count()['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut  Parch\n",
      "0.0      0        1.000000\n",
      "         1        0.657143\n",
      "         2        0.538462\n",
      "1.0      0        0.380282\n",
      "         1        0.400000\n",
      "         2        0.533333\n",
      "         3        0.000000\n",
      "2.0      0        0.304813\n",
      "         1        0.533333\n",
      "         2        0.666667\n",
      "         3        1.000000\n",
      "         4        0.000000\n",
      "3.0      0        0.411765\n",
      "         1        0.526316\n",
      "         2        0.750000\n",
      "         5        0.250000\n",
      "4.0      0        0.373134\n",
      "         1        0.571429\n",
      "         2        0.333333\n",
      "         3        0.000000\n",
      "         4        0.000000\n",
      "         5        0.000000\n",
      "         6        0.000000\n",
      "5.0      0        0.368421\n",
      "         1        0.625000\n",
      "         2        0.000000\n",
      "         3        1.000000\n",
      "6.0      0        0.333333\n",
      "         1        0.333333\n",
      "         4        0.000000\n",
      "7.0      0        0.000000\n",
      "         1        0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Parch  Age_Cut\n",
      "0      0.0        1.000000\n",
      "       1.0        0.380282\n",
      "       2.0        0.304813\n",
      "       3.0        0.411765\n",
      "       4.0        0.373134\n",
      "       5.0        0.368421\n",
      "       6.0        0.333333\n",
      "       7.0        0.000000\n",
      "1      0.0        0.657143\n",
      "       1.0        0.400000\n",
      "       2.0        0.533333\n",
      "       3.0        0.526316\n",
      "       4.0        0.571429\n",
      "       5.0        0.625000\n",
      "       6.0        0.333333\n",
      "       7.0        0.000000\n",
      "2      0.0        0.538462\n",
      "       1.0        0.533333\n",
      "       2.0        0.666667\n",
      "       3.0        0.750000\n",
      "       4.0        0.333333\n",
      "       5.0        0.000000\n",
      "3      1.0        0.000000\n",
      "       2.0        1.000000\n",
      "       4.0        0.000000\n",
      "       5.0        1.000000\n",
      "4      2.0        0.000000\n",
      "       4.0        0.000000\n",
      "       6.0        0.000000\n",
      "5      3.0        0.250000\n",
      "       4.0        0.000000\n",
      "6      4.0        0.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_new_features.groupby(['Age_Cut','Parch']).sum()['Survived'] / train_data_with_new_features.groupby(['Age_Cut','Parch']).count()['Survived'])\n",
    "print(train_data_with_new_features.groupby(['Parch','Age_Cut']).sum()['Survived'] / train_data_with_new_features.groupby(['Parch','Age_Cut']).count()['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아니 근데 0~9세중에 Parch가 0인 1명은 대체 뭐지?<br>\n",
    "근데 또 어떻게 다 살았지?<br>\n",
    "지금 부모가 있는 자녀들이 더 많이 산건가?<br>\n",
    "그걸 잘 모르겠음.<br>\n",
    "근데 생각해보니깐 **꼬마들은 다 부모 있는거 아닌가?<br>\n",
    "그럼 그게 0~9세 + Parch > 0 이 유의미한 변수라고 보기 힘들지 않나?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked  Sex\n",
       "1.0       1      0.305263\n",
       "          2      0.876712\n",
       "2.0       1      0.073171\n",
       "          2      0.750000\n",
       "3.0       1      0.174603\n",
       "          2      0.689655\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_new_features.groupby(['Sex','Pclass','Age_Cut']).sum()['Survived'] / train_data_with_new_features.groupby(['Sex','Pclass','Age_Cut']).count()['Survived']\n",
    "train_data_with_new_features.groupby(['Embarked','Sex']).sum()['Survived'] / train_data_with_new_features.groupby(['Embarked','Sex']).count()['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut  Sex\n",
      "0.0      1      0.593750\n",
      "         2      0.633333\n",
      "1.0      1      0.122807\n",
      "         2      0.755556\n",
      "2.0      1      0.168919\n",
      "         2      0.722222\n",
      "3.0      1      0.214953\n",
      "         2      0.833333\n",
      "4.0      1      0.210526\n",
      "         2      0.687500\n",
      "5.0      1      0.133333\n",
      "         2      0.888889\n",
      "6.0      1      0.133333\n",
      "         2      1.000000\n",
      "7.0      1      0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Sex  Age_Cut\n",
      "1    0.0        0.593750\n",
      "     1.0        0.122807\n",
      "     2.0        0.168919\n",
      "     3.0        0.214953\n",
      "     4.0        0.210526\n",
      "     5.0        0.133333\n",
      "     6.0        0.133333\n",
      "     7.0        0.000000\n",
      "2    0.0        0.633333\n",
      "     1.0        0.755556\n",
      "     2.0        0.722222\n",
      "     3.0        0.833333\n",
      "     4.0        0.687500\n",
      "     5.0        0.888889\n",
      "     6.0        1.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_new_features.groupby(['Age_Cut','Sex']).sum()['Survived'] / train_data_with_new_features.groupby(['Age_Cut','Sex']).count()['Survived']\n",
    "     )\n",
    "print(train_data_with_new_features.groupby(['Sex','Age_Cut']).sum()['Survived'] / train_data_with_new_features.groupby(['Sex','Age_Cut']).count()['Survived']\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상상력이 없나...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagination\n",
    "\n",
    "1. 여자면서 1st Class면 다 살았다고 해도 96%는 맞아(여자+2nd class도 92%는 맞아).\n",
    "2. 일단 70대는 죽었다고 판단해도 될거 같아. → 구조원칙 상으로도 애기들부터 살린다네(근데 여자는 70대가 없음. 근데 50~60대가 거의 다삼. 쓰기 어려울듯)\n",
    "3. 여자는 나이 대 별로 차이도 많이 안나고, 심지어 50~60대 여자들이 엄청나게 살았는데 남자는 \n",
    "    나이대 까지 상관없이 그냥 거의 다 죽음\n",
    "\n",
    "4. 남편이 같이 탄 여자? -> 찾아봤는데 딱히...\n",
    "5. 부모 혹은 자녀가 있는 사람? → 찾아봤는데 딱히...\n",
    "\n",
    "\n",
    "**여자 + 1st, 2nd Class라도 해서 하나 만들자**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sex_pclass_mask =(train_data_with_new_features['Sex']==2) & (train_data_with_new_features.Pclass !=  3) \n",
    "train_data_with_new_features['women_1st_2nd_class']=sex_pclass_mask.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.169718</td>\n",
       "      <td>-0.080072</td>\n",
       "      <td>0.562359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.349140</td>\n",
       "      <td>-0.500673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.090459</td>\n",
       "      <td>0.658233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.980262</td>\n",
       "      <td>0.080084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>-0.300555</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.188898</td>\n",
       "      <td>0.085551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.226311</td>\n",
       "      <td>0.090733</td>\n",
       "      <td>0.354893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.169718</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.226311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040965</td>\n",
       "      <td>-0.090566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Cut</th>\n",
       "      <td>-0.080072</td>\n",
       "      <td>-0.349140</td>\n",
       "      <td>-0.090459</td>\n",
       "      <td>0.980262</td>\n",
       "      <td>-0.300555</td>\n",
       "      <td>-0.188898</td>\n",
       "      <td>0.090733</td>\n",
       "      <td>-0.040965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "      <td>0.562359</td>\n",
       "      <td>-0.500673</td>\n",
       "      <td>0.658233</td>\n",
       "      <td>0.080084</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.085551</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>-0.090566</td>\n",
       "      <td>0.078868</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Survived    Pclass       Sex       Age     SibSp  \\\n",
       "Survived             1.000000 -0.338481  0.543351 -0.077221 -0.035322   \n",
       "Pclass              -0.338481  1.000000 -0.131900 -0.369226  0.083081   \n",
       "Sex                  0.543351 -0.131900  1.000000 -0.093254  0.114631   \n",
       "Age                 -0.077221 -0.369226 -0.093254  1.000000 -0.308247   \n",
       "SibSp               -0.035322  0.083081  0.114631 -0.308247  1.000000   \n",
       "Parch                0.081629  0.018443  0.245489 -0.189119  0.414838   \n",
       "Fare                 0.257307 -0.549500  0.182333  0.096067  0.159651   \n",
       "Embarked            -0.169718  0.164681 -0.110320 -0.032565  0.068900   \n",
       "Age_Cut             -0.080072 -0.349140 -0.090459  0.980262 -0.300555   \n",
       "women_1st_2nd_class  0.562359 -0.500673  0.658233  0.080084  0.000230   \n",
       "\n",
       "                        Parch      Fare  Embarked   Age_Cut  \\\n",
       "Survived             0.081629  0.257307 -0.169718 -0.080072   \n",
       "Pclass               0.018443 -0.549500  0.164681 -0.349140   \n",
       "Sex                  0.245489  0.182333 -0.110320 -0.090459   \n",
       "Age                 -0.189119  0.096067 -0.032565  0.980262   \n",
       "SibSp                0.414838  0.159651  0.068900 -0.300555   \n",
       "Parch                1.000000  0.216225  0.040449 -0.188898   \n",
       "Fare                 0.216225  1.000000 -0.226311  0.090733   \n",
       "Embarked             0.040449 -0.226311  1.000000 -0.040965   \n",
       "Age_Cut             -0.188898  0.090733 -0.040965  1.000000   \n",
       "women_1st_2nd_class  0.085551  0.354893 -0.090566  0.078868   \n",
       "\n",
       "                     women_1st_2nd_class  \n",
       "Survived                        0.562359  \n",
       "Pclass                         -0.500673  \n",
       "Sex                             0.658233  \n",
       "Age                             0.080084  \n",
       "SibSp                           0.000230  \n",
       "Parch                           0.085551  \n",
       "Fare                            0.354893  \n",
       "Embarked                       -0.090566  \n",
       "Age_Cut                         0.078868  \n",
       "women_1st_2nd_class             1.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_new_features.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "1. ***근데 만들었어도 어떻게 객관적으로 확인하지? 지금처럼 하면 되나?***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재까지! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked  \\\n",
       "PassengerId                                                                  \n",
       "1                   0       3    1  22.0      1      0    7.2500       3.0   \n",
       "2                   1       1    2  38.0      1      0   71.2833       1.0   \n",
       "3                   1       3    2  26.0      0      0    7.9250       3.0   \n",
       "4                   1       1    2  35.0      1      0   53.1000       3.0   \n",
       "5                   0       3    1  35.0      0      0    8.0500       3.0   \n",
       "6                   0       3    1   NaN      0      0    8.4583       2.0   \n",
       "7                   0       1    1  54.0      0      0   51.8625       3.0   \n",
       "8                   0       3    1   2.0      3      1   21.0750       3.0   \n",
       "9                   1       3    2  27.0      0      2   11.1333       3.0   \n",
       "10                  1       2    2  14.0      1      0   30.0708       1.0   \n",
       "11                  1       3    2   4.0      1      1   16.7000       3.0   \n",
       "12                  1       1    2  58.0      0      0   26.5500       3.0   \n",
       "13                  0       3    1  20.0      0      0    8.0500       3.0   \n",
       "14                  0       3    1  39.0      1      5   31.2750       3.0   \n",
       "15                  0       3    2  14.0      0      0    7.8542       3.0   \n",
       "16                  1       2    2  55.0      0      0   16.0000       3.0   \n",
       "17                  0       3    1   2.0      4      1   29.1250       2.0   \n",
       "18                  1       2    1   NaN      0      0   13.0000       3.0   \n",
       "19                  0       3    2  31.0      1      0   18.0000       3.0   \n",
       "20                  1       3    2   NaN      0      0    7.2250       1.0   \n",
       "21                  0       2    1  35.0      0      0   26.0000       3.0   \n",
       "22                  1       2    1  34.0      0      0   13.0000       3.0   \n",
       "23                  1       3    2  15.0      0      0    8.0292       2.0   \n",
       "24                  1       1    1  28.0      0      0   35.5000       3.0   \n",
       "25                  0       3    2   8.0      3      1   21.0750       3.0   \n",
       "26                  1       3    2  38.0      1      5   31.3875       3.0   \n",
       "27                  0       3    1   NaN      0      0    7.2250       1.0   \n",
       "28                  0       1    1  19.0      3      2  263.0000       3.0   \n",
       "29                  1       3    2   NaN      0      0    7.8792       2.0   \n",
       "30                  0       3    1   NaN      0      0    7.8958       3.0   \n",
       "...               ...     ...  ...   ...    ...    ...       ...       ...   \n",
       "862                 0       2    1  21.0      1      0   11.5000       3.0   \n",
       "863                 1       1    2  48.0      0      0   25.9292       3.0   \n",
       "864                 0       3    2   NaN      8      2   69.5500       3.0   \n",
       "865                 0       2    1  24.0      0      0   13.0000       3.0   \n",
       "866                 1       2    2  42.0      0      0   13.0000       3.0   \n",
       "867                 1       2    2  27.0      1      0   13.8583       1.0   \n",
       "868                 0       1    1  31.0      0      0   50.4958       3.0   \n",
       "869                 0       3    1   NaN      0      0    9.5000       3.0   \n",
       "870                 1       3    1   4.0      1      1   11.1333       3.0   \n",
       "871                 0       3    1  26.0      0      0    7.8958       3.0   \n",
       "872                 1       1    2  47.0      1      1   52.5542       3.0   \n",
       "873                 0       1    1  33.0      0      0    5.0000       3.0   \n",
       "874                 0       3    1  47.0      0      0    9.0000       3.0   \n",
       "875                 1       2    2  28.0      1      0   24.0000       1.0   \n",
       "876                 1       3    2  15.0      0      0    7.2250       1.0   \n",
       "877                 0       3    1  20.0      0      0    9.8458       3.0   \n",
       "878                 0       3    1  19.0      0      0    7.8958       3.0   \n",
       "879                 0       3    1   NaN      0      0    7.8958       3.0   \n",
       "880                 1       1    2  56.0      0      1   83.1583       1.0   \n",
       "881                 1       2    2  25.0      0      1   26.0000       3.0   \n",
       "882                 0       3    1  33.0      0      0    7.8958       3.0   \n",
       "883                 0       3    2  22.0      0      0   10.5167       3.0   \n",
       "884                 0       2    1  28.0      0      0   10.5000       3.0   \n",
       "885                 0       3    1  25.0      0      0    7.0500       3.0   \n",
       "886                 0       3    2  39.0      0      5   29.1250       2.0   \n",
       "887                 0       2    1  27.0      0      0   13.0000       3.0   \n",
       "888                 1       1    2  19.0      0      0   30.0000       3.0   \n",
       "889                 0       3    2   NaN      1      2   23.4500       3.0   \n",
       "890                 1       1    1  26.0      0      0   30.0000       1.0   \n",
       "891                 0       3    1  32.0      0      0    7.7500       2.0   \n",
       "\n",
       "             Age_Cut  women_1st_2nd_class  \n",
       "PassengerId                                \n",
       "1                2.0                  0.0  \n",
       "2                3.0                  1.0  \n",
       "3                2.0                  0.0  \n",
       "4                3.0                  1.0  \n",
       "5                3.0                  0.0  \n",
       "6                NaN                  0.0  \n",
       "7                5.0                  0.0  \n",
       "8                0.0                  0.0  \n",
       "9                2.0                  0.0  \n",
       "10               1.0                  1.0  \n",
       "11               0.0                  0.0  \n",
       "12               5.0                  1.0  \n",
       "13               2.0                  0.0  \n",
       "14               3.0                  0.0  \n",
       "15               1.0                  0.0  \n",
       "16               5.0                  1.0  \n",
       "17               0.0                  0.0  \n",
       "18               NaN                  0.0  \n",
       "19               3.0                  0.0  \n",
       "20               NaN                  0.0  \n",
       "21               3.0                  0.0  \n",
       "22               3.0                  0.0  \n",
       "23               1.0                  0.0  \n",
       "24               2.0                  0.0  \n",
       "25               0.0                  0.0  \n",
       "26               3.0                  0.0  \n",
       "27               NaN                  0.0  \n",
       "28               1.0                  0.0  \n",
       "29               NaN                  0.0  \n",
       "30               NaN                  0.0  \n",
       "...              ...                  ...  \n",
       "862              2.0                  0.0  \n",
       "863              4.0                  1.0  \n",
       "864              NaN                  0.0  \n",
       "865              2.0                  0.0  \n",
       "866              4.0                  1.0  \n",
       "867              2.0                  1.0  \n",
       "868              3.0                  0.0  \n",
       "869              NaN                  0.0  \n",
       "870              0.0                  0.0  \n",
       "871              2.0                  0.0  \n",
       "872              4.0                  1.0  \n",
       "873              3.0                  0.0  \n",
       "874              4.0                  0.0  \n",
       "875              2.0                  1.0  \n",
       "876              1.0                  0.0  \n",
       "877              2.0                  0.0  \n",
       "878              1.0                  0.0  \n",
       "879              NaN                  0.0  \n",
       "880              5.0                  1.0  \n",
       "881              2.0                  1.0  \n",
       "882              3.0                  0.0  \n",
       "883              2.0                  0.0  \n",
       "884              2.0                  0.0  \n",
       "885              2.0                  0.0  \n",
       "886              3.0                  0.0  \n",
       "887              2.0                  0.0  \n",
       "888              1.0                  1.0  \n",
       "889              NaN                  0.0  \n",
       "890              2.0                  0.0  \n",
       "891              3.0                  0.0  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing For Maching Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 일단 Null값들 처리해야됨. \n",
    "null이 있었던 column은 총 2개 -> Age, Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_train_data = train_data_with_new_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 10 columns):\n",
      "Survived               891 non-null int64\n",
      "Pclass                 891 non-null int64\n",
      "Sex                    891 non-null int64\n",
      "Age                    714 non-null float64\n",
      "SibSp                  891 non-null int64\n",
      "Parch                  891 non-null int64\n",
      "Fare                   891 non-null float64\n",
      "Embarked               889 non-null float64\n",
      "Age_Cut                713 non-null float64\n",
      "women_1st_2nd_class    891 non-null float64\n",
      "dtypes: float64(5), int64(5)\n",
      "memory usage: 76.6 KB\n"
     ]
    }
   ],
   "source": [
    "pre_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd21ae0cf8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSYWw0CWpEP8Hq/bCllhlvlUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd21fefb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_train_data['Age'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd229bc978>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1LjLHpJatz/A9pO2wPfjdn1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd21a89668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_train_data['Embarked'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age에 null이 좀 많고, <br>\n",
    "embarked에는 2개<br>\n",
    "embarked row는 어쩔 수 없이 날려야 될 것 같고, <br>\n",
    "**Age는 Right-Skewed -> Median으로 채우자**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_train_data = pre_train_data.dropna(subset=[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age_median = float(pre_train_data['Age'].median())\n",
    "pre_train_data['Age'].fillna(age_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Index.drop of Int64Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "            ...\n",
       "            882, 883, 884, 885, 886, 887, 888, 889, 890, 891],\n",
       "           dtype='int64', name='PassengerId', length=889)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_train_data.index.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_train_data = pre_train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = pd.DataFrame(pre_train_data['Survived'])\n",
    "train_x = pre_train_data.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding<br>\n",
    "Y - Survived <br>\n",
    "X - pclasss, sex, embarked를 one-hot encoding 해야 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pclass_encoded = pd.get_dummies(train_x['Pclass'])\n",
    "sex_encoded = pd.get_dummies(train_x['Sex'])\n",
    "embarked_encoded = pd.get_dummies(train_x['Embarked'])\n",
    "y_encoded = pd.get_dummies(train_y['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x_encoded = train_x.drop(['Pclass', 'Embarked', 'Sex'],axis=1)\n",
    "train_y_encoded = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_encoded = pd.concat([train_x_encoded ,pclass_encoded, sex_encoded, embarked_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  SibSp  Parch      Fare  Age_Cut  women_1st_2nd_class  1  2  3  1  \\\n",
      "0    22.0      1      0    7.2500      2.0                  0.0  0  0  1  1   \n",
      "1    38.0      1      0   71.2833      3.0                  1.0  1  0  0  0   \n",
      "2    26.0      0      0    7.9250      2.0                  0.0  0  0  1  0   \n",
      "3    35.0      1      0   53.1000      3.0                  1.0  1  0  0  0   \n",
      "4    35.0      0      0    8.0500      3.0                  0.0  0  0  1  1   \n",
      "5    28.0      0      0    8.4583      NaN                  0.0  0  0  1  1   \n",
      "6    54.0      0      0   51.8625      5.0                  0.0  1  0  0  1   \n",
      "7     2.0      3      1   21.0750      0.0                  0.0  0  0  1  1   \n",
      "8    27.0      0      2   11.1333      2.0                  0.0  0  0  1  0   \n",
      "9    14.0      1      0   30.0708      1.0                  1.0  0  1  0  0   \n",
      "10    4.0      1      1   16.7000      0.0                  0.0  0  0  1  0   \n",
      "11   58.0      0      0   26.5500      5.0                  1.0  1  0  0  0   \n",
      "12   20.0      0      0    8.0500      2.0                  0.0  0  0  1  1   \n",
      "13   39.0      1      5   31.2750      3.0                  0.0  0  0  1  1   \n",
      "14   14.0      0      0    7.8542      1.0                  0.0  0  0  1  0   \n",
      "15   55.0      0      0   16.0000      5.0                  1.0  0  1  0  0   \n",
      "16    2.0      4      1   29.1250      0.0                  0.0  0  0  1  1   \n",
      "17   28.0      0      0   13.0000      NaN                  0.0  0  1  0  1   \n",
      "18   31.0      1      0   18.0000      3.0                  0.0  0  0  1  0   \n",
      "19   28.0      0      0    7.2250      NaN                  0.0  0  0  1  0   \n",
      "20   35.0      0      0   26.0000      3.0                  0.0  0  1  0  1   \n",
      "21   34.0      0      0   13.0000      3.0                  0.0  0  1  0  1   \n",
      "22   15.0      0      0    8.0292      1.0                  0.0  0  0  1  0   \n",
      "23   28.0      0      0   35.5000      2.0                  0.0  1  0  0  1   \n",
      "24    8.0      3      1   21.0750      0.0                  0.0  0  0  1  0   \n",
      "25   38.0      1      5   31.3875      3.0                  0.0  0  0  1  0   \n",
      "26   28.0      0      0    7.2250      NaN                  0.0  0  0  1  1   \n",
      "27   19.0      3      2  263.0000      1.0                  0.0  1  0  0  1   \n",
      "28   28.0      0      0    7.8792      NaN                  0.0  0  0  1  0   \n",
      "29   28.0      0      0    7.8958      NaN                  0.0  0  0  1  1   \n",
      "..    ...    ...    ...       ...      ...                  ... .. .. .. ..   \n",
      "859  21.0      1      0   11.5000      2.0                  0.0  0  1  0  1   \n",
      "860  48.0      0      0   25.9292      4.0                  1.0  1  0  0  0   \n",
      "861  28.0      8      2   69.5500      NaN                  0.0  0  0  1  0   \n",
      "862  24.0      0      0   13.0000      2.0                  0.0  0  1  0  1   \n",
      "863  42.0      0      0   13.0000      4.0                  1.0  0  1  0  0   \n",
      "864  27.0      1      0   13.8583      2.0                  1.0  0  1  0  0   \n",
      "865  31.0      0      0   50.4958      3.0                  0.0  1  0  0  1   \n",
      "866  28.0      0      0    9.5000      NaN                  0.0  0  0  1  1   \n",
      "867   4.0      1      1   11.1333      0.0                  0.0  0  0  1  1   \n",
      "868  26.0      0      0    7.8958      2.0                  0.0  0  0  1  1   \n",
      "869  47.0      1      1   52.5542      4.0                  1.0  1  0  0  0   \n",
      "870  33.0      0      0    5.0000      3.0                  0.0  1  0  0  1   \n",
      "871  47.0      0      0    9.0000      4.0                  0.0  0  0  1  1   \n",
      "872  28.0      1      0   24.0000      2.0                  1.0  0  1  0  0   \n",
      "873  15.0      0      0    7.2250      1.0                  0.0  0  0  1  0   \n",
      "874  20.0      0      0    9.8458      2.0                  0.0  0  0  1  1   \n",
      "875  19.0      0      0    7.8958      1.0                  0.0  0  0  1  1   \n",
      "876  28.0      0      0    7.8958      NaN                  0.0  0  0  1  1   \n",
      "877  56.0      0      1   83.1583      5.0                  1.0  1  0  0  0   \n",
      "878  25.0      0      1   26.0000      2.0                  1.0  0  1  0  0   \n",
      "879  33.0      0      0    7.8958      3.0                  0.0  0  0  1  1   \n",
      "880  22.0      0      0   10.5167      2.0                  0.0  0  0  1  0   \n",
      "881  28.0      0      0   10.5000      2.0                  0.0  0  1  0  1   \n",
      "882  25.0      0      0    7.0500      2.0                  0.0  0  0  1  1   \n",
      "883  39.0      0      5   29.1250      3.0                  0.0  0  0  1  0   \n",
      "884  27.0      0      0   13.0000      2.0                  0.0  0  1  0  1   \n",
      "885  19.0      0      0   30.0000      1.0                  1.0  1  0  0  0   \n",
      "886  28.0      1      2   23.4500      NaN                  0.0  0  0  1  0   \n",
      "887  26.0      0      0   30.0000      2.0                  0.0  1  0  0  1   \n",
      "888  32.0      0      0    7.7500      3.0                  0.0  0  0  1  1   \n",
      "\n",
      "     2  1.0  2.0  3.0  \n",
      "0    0    0    0    1  \n",
      "1    1    1    0    0  \n",
      "2    1    0    0    1  \n",
      "3    1    0    0    1  \n",
      "4    0    0    0    1  \n",
      "5    0    0    1    0  \n",
      "6    0    0    0    1  \n",
      "7    0    0    0    1  \n",
      "8    1    0    0    1  \n",
      "9    1    1    0    0  \n",
      "10   1    0    0    1  \n",
      "11   1    0    0    1  \n",
      "12   0    0    0    1  \n",
      "13   0    0    0    1  \n",
      "14   1    0    0    1  \n",
      "15   1    0    0    1  \n",
      "16   0    0    1    0  \n",
      "17   0    0    0    1  \n",
      "18   1    0    0    1  \n",
      "19   1    1    0    0  \n",
      "20   0    0    0    1  \n",
      "21   0    0    0    1  \n",
      "22   1    0    1    0  \n",
      "23   0    0    0    1  \n",
      "24   1    0    0    1  \n",
      "25   1    0    0    1  \n",
      "26   0    1    0    0  \n",
      "27   0    0    0    1  \n",
      "28   1    0    1    0  \n",
      "29   0    0    0    1  \n",
      "..  ..  ...  ...  ...  \n",
      "859  0    0    0    1  \n",
      "860  1    0    0    1  \n",
      "861  1    0    0    1  \n",
      "862  0    0    0    1  \n",
      "863  1    0    0    1  \n",
      "864  1    1    0    0  \n",
      "865  0    0    0    1  \n",
      "866  0    0    0    1  \n",
      "867  0    0    0    1  \n",
      "868  0    0    0    1  \n",
      "869  1    0    0    1  \n",
      "870  0    0    0    1  \n",
      "871  0    0    0    1  \n",
      "872  1    1    0    0  \n",
      "873  1    1    0    0  \n",
      "874  0    0    0    1  \n",
      "875  0    0    0    1  \n",
      "876  0    0    0    1  \n",
      "877  1    1    0    0  \n",
      "878  1    0    0    1  \n",
      "879  0    0    0    1  \n",
      "880  1    0    0    1  \n",
      "881  0    0    0    1  \n",
      "882  0    0    0    1  \n",
      "883  1    0    1    0  \n",
      "884  0    0    0    1  \n",
      "885  1    0    0    1  \n",
      "886  1    0    0    1  \n",
      "887  0    1    0    0  \n",
      "888  0    0    1    0  \n",
      "\n",
      "[889 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_x_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age_Cut은 Nan값을 채우기 전에 만든 것임으로<br>\n",
    "Age가 NaN이였던 Row의 Age_Cut은 아직도 NaN임.<br>\n",
    "그 친구들 채워야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_with_ages = train_x_encoded.copy()\n",
    "train_x_encoded['Age_Cut'] = pd.cut(train_data_with_ages['Age'], labels=labels,\n",
    "bins=bins, include_lowest = True)\n",
    "\n",
    "train_x_encoded['Age_Cut'] = train_x_encoded['Age_Cut'].astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age_Cut</th>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch  Fare  Age_Cut  women_1st_2nd_class  1  2  3  1  2  \\\n",
       "629  80.0      0      0  30.0      NaN                  0.0  1  0  0  1  0   \n",
       "\n",
       "     1.0  2.0  3.0  \n",
       "629    0    0    1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_encoded[train_x_encoded['Age_Cut'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_encoded[train_x_encoded['Age_Cut'].isnull()]=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age_Cut</th>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Age, SibSp, Parch, Fare, Age_Cut, women_1st_2nd_class, 1, 2, 3, 1, 2, 1.0, 2.0, 3.0]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_encoded[train_x_encoded['Age_Cut'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 889 entries, 0 to 888\n",
      "Data columns (total 14 columns):\n",
      "Age                    889 non-null float64\n",
      "SibSp                  889 non-null int64\n",
      "Parch                  889 non-null int64\n",
      "Fare                   889 non-null float64\n",
      "Age_Cut                889 non-null float64\n",
      "women_1st_2nd_class    889 non-null float64\n",
      "1                      889 non-null uint8\n",
      "2                      889 non-null uint8\n",
      "3                      889 non-null uint8\n",
      "1                      889 non-null uint8\n",
      "2                      889 non-null uint8\n",
      "1.0                    889 non-null uint8\n",
      "2.0                    889 non-null uint8\n",
      "3.0                    889 non-null uint8\n",
      "dtypes: float64(4), int64(2), uint8(8)\n",
      "memory usage: 48.7 KB\n"
     ]
    }
   ],
   "source": [
    "train_x_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_encoded['SibSp'] = train_x_encoded['SibSp'].astype(float) \n",
    "train_x_encoded['Parch'] = train_x_encoded['Parch'].astype(float) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "Age, Fare, SibSp, Parch, Age_Cut을 Scaling 할 것<br>\n",
    "stdscaler or MinMax Scaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "before_scaler = train_x_encoded[['Age', 'Fare', 'SibSp', 'Parch', 'Age_Cut']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "after_scaler = pd.DataFrame(stdscaler.fit_transform(before_scaler),\n",
    "             columns=before_scaler.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_x= train_x_encoded.drop(['Age', 'Fare', 'SibSp', 'Parch'],\n",
    "                                                 axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_scaled = pd.concat([after_scaler, drop_x], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 15)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train x : train_x_scaled<br>\n",
    "train y : train_y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_x_scaled.values\n",
    "y = train_y.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "***Ground Truth***<br>\n",
    "Accuracy를 구하려면 최소 하나로 몰빵 예측했을때 보다는 높아야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38245219347581555\n"
     ]
    }
   ],
   "source": [
    "print(sum(y==1)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6175478065241845\n"
     ]
    }
   ],
   "source": [
    "print(sum(y==0)/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다 살았다고 예측하면 38% 맞고, 다 죽었다고 예측하면 61% 맞음.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logitstic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79775281 0.79775281 0.76404494 0.83146067 0.83146067 0.79775281\n",
      " 0.82022472 0.79775281 0.84269663 0.82954545]\n",
      "mean:  0.811044433094995\n",
      "Standard Deviation:  0.022754546448635508\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(log_reg, X, y, cv=10)\n",
    "print(scores)\n",
    "print(\"mean: \", np.mean(scores))\n",
    "print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver_list = ['lbfgs','sag', 'saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver lbfgs  scores\n",
      "mean:  0.809920837589377\n",
      "Standard Deviation:  0.024171258578039777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver sag  scores\n",
      "mean:  0.7952885597548518\n",
      "Standard Deviation:  0.03712458015700324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver saga  scores\n",
      "mean:  0.7874106230847804\n",
      "Standard Deviation:  0.04242513819923914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in solver_list:\n",
    "    softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=i, C=10)\n",
    "    softmax_reg.fit(X, y)\n",
    "    scores = cross_val_score(softmax_reg, X, y, cv=10)\n",
    "    print('solver', i, ' scores')\n",
    "    print(\"mean: \", np.mean(scores))\n",
    "    print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy 79~81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.001: 0.6838993871297241, 0.01: 0.7873723186925434, 0.1: 0.7952374872318693, 1: 0.7817671092951991, 10: 0.7851506639427988, 100: 0.7660495403472931, 1000: 0.6904494382022472}\n",
      "The Best C value is 0.1\n",
      "The rmse of C= 0.1 is  0.7952374872318693\n"
     ]
    }
   ],
   "source": [
    "c_dict = {}\n",
    "for i in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    linear_svc =LinearSVC(C =i, loss=\"hinge\")\n",
    "    linear_svc.fit(X, y)\n",
    "    scores = cross_val_score(linear_svc, X, y, cv=10)\n",
    "    c_dict[i]=np.mean(scores)\n",
    "    \n",
    "print(c_dict)    \n",
    "for key, value in c_dict.items():\n",
    "    if value == max(c_dict.values()):\n",
    "        print(\"The Best C value is\", key)\n",
    "        print(\"The rmse of C=\", key, \"is \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.001: 0.6838993871297241, 0.005: 0.7941138917262512, 0.01: 0.7873723186925434, 0.05: 0.7873723186925434, 0.1: 0.7952374872318693, 0.3: 0.7873723186925434, 0.9: 0.7828907048008171, 1: 0.7828907048008171}\n",
      "The Best C value is 0.1\n",
      "The rmse of C= 0.1 is  0.7952374872318693\n"
     ]
    }
   ],
   "source": [
    "c_dict = {}\n",
    "for i in [0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 0.9, 1]:\n",
    "    linear_svc =LinearSVC(C =i, loss=\"hinge\")\n",
    "    linear_svc.fit(X, y)\n",
    "    scores = cross_val_score(linear_svc, X, y, cv=10)\n",
    "    c_dict[i]=np.mean(scores)\n",
    "    \n",
    "print(c_dict)    \n",
    "for key, value in c_dict.items():\n",
    "    if value == max(c_dict.values()):\n",
    "        print(\"The Best C value is\", key)\n",
    "        print(\"The rmse of C=\", key, \"is \", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "------\n",
    "**Feedback**<br>\n",
    "1, 10, 100 이런식으로 넓은 범위의 값들을 먼저 대입 → 값을 돌리고 차이를 살핀다.<br>\n",
    "그래프가 어떻게 나오는지 보고, Skewed된 그래프 쪽으로 점차 값을 줄여 간다.<br>\n",
    "한번에 500개씩 넣고 할 필요가 없음. 범위를 점점 좁히는 작업."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy 79%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Non-Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2, 0.001): 0.7997574055158324, (2, 0.01): 0.8110188968335036, (2, 0.1): 0.8301583248212461, (2, 1): 0.8256639427987743, (2, 10): 0.8043283963227783, (2, 100): 0.7447522982635342, (2, 1000): 0.7389427987742595, (3, 0.001): 0.8144024514811031, (3, 0.01): 0.827885597548519, (3, 0.1): 0.8054647599591419, (3, 1): 0.7907814096016343, (3, 10): 0.7095888661899898, (3, 100): 0.6750510725229825, (3, 1000): 0.7221144024514812, (4, 0.001): 0.8222803881511747, (4, 0.01): 0.8110699693564862, (4, 0.1): 0.7705439223697651, (4, 1): 0.7604826353421859, (4, 10): 0.7458120531154238, (4, 100): 0.6423774259448416, (4, 1000): 0.6738891726251277}\n",
      "The Best C value is 0.1\n",
      "The Best Degree value is 2\n",
      "The score is  0.8301583248212461\n"
     ]
    }
   ],
   "source": [
    "p_dict ={}\n",
    "\n",
    "for i in list([2, 3, 4]):\n",
    "    poly_features = PolynomialFeatures(degree=i)\n",
    "    x_poly = poly_features.fit_transform(X)\n",
    "    \n",
    "    for j in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        linear_svc = LinearSVC(C =j, loss=\"hinge\")\n",
    "        linear_svc.fit(x_poly, y)\n",
    "        scores = cross_val_score(linear_svc, x_poly,y, cv=10)\n",
    "        p_dict[i, j]=np.mean(scores)\n",
    "        #i= degree, j=C\n",
    "                \n",
    "print(p_dict)    \n",
    "for key, value in p_dict.items():\n",
    "    if value == max(p_dict.values()):\n",
    "        print(\"The Best C value is\", key[1])\n",
    "        print(\"The Best Degree value is\", key[0])\n",
    "        print(\"The score is \", value)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Accuracy 82%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV \n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    coef0_param = [0.1, 1, 10, 100, 1000]\n",
    "    degree_param = [2, 3, 4, 5, 6]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'coef0':coef0_param, 'degree': degree_param}\n",
    "    grid_search = GridSearchCV(SVC(kernel=\"poly\"), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = svm_param_selection(X, y, 5)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_dist = {\"C\": ,\n",
    "#               \"max_features\": sp_randint(1, 11),\n",
    "#               \"min_samples_split\": sp_randint(2, 11),\n",
    "#               \"bootstrap\": [True, False],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # run randomized search\n",
    "# n_iter_search = 20\n",
    "# random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "#                                    n_iter=n_iter_search, cv=5)\n",
    "\n",
    "# start = time()\n",
    "# random_search.fit(X, y)\n",
    "# print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "#       \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "# report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# svm_clf = SVC(kernel=\"poly\")\n",
    "# grid_search = GridSearchCV(svm_clf, param_grid, cv=5,\n",
    "#                            return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# svm_clf  = SVC(kernel=\"poly\", degree=3, coef0=5, C=10)\n",
    "# scores = cross_val_score(linear_svc, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "# rmse_scores = np.sqrt(-scores)\n",
    "# print(np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가우시안 BRF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_clf  = SVC(kernel=\"rbf\", gamma=5, coef0=5, C=0.001)\n",
    "scores = cross_val_score(linear_svc, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.7784601634320735\n",
      "Standard Deviation:  0.04878577113347266\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tree_reg, X, y, cv=10)\n",
    "print(\"mean: \", np.mean(scores))\n",
    "print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Accuracy 77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_reg = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.8290219611848825\n",
      "Standard Deviation:  0.04813895001456675\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(forest_reg, X, y, cv=10)\n",
    "print(\"mean: \", np.mean(scores))\n",
    "print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Accuracy 83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf_hard = SVC()\n",
    "svm_clf_soft = SVC(probability=True)\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "        estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf_hard)],\n",
    "        voting= 'hard')\n",
    "\n",
    "voting_clf_soft=VotingClassifier(\n",
    "        estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf_soft)],\n",
    "        voting= 'soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 1)\n",
      "(889,)\n"
     ]
    }
   ],
   "source": [
    "y1=y.reshape((-1, 1))\n",
    "print(y1.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.8346654749744638\n",
      "Standard Deviation:  0.040452148517987244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(voting_clf_soft, X, y1, cv=10)\n",
    "print(\"mean: \", np.mean(scores))\n",
    "print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy 83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "        LogisticRegression(), n_estimators = 50,\n",
    "        max_samples=50, bootstrap=True, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=50, n_estimators=50, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.8098697650663942\n",
      "Standard Deviation:  0.03011755221952\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(bag_clf, X, y, cv=10)\n",
    "print(\"mean: \", np.mean(scores))\n",
    "print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "        LogisticRegression(), n_estimators = 50,\n",
    "        max_samples=50, bootstrap=False, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.8019918283963229\n",
      "Standard Deviation:  0.03168806202288174\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(bag_clf, X, y, cv=10)\n",
    "print(\"mean: \", np.mean(scores))\n",
    "print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Accuracy 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(), n_estimators=200,\n",
    "        algorithm=\"SAMME.R\", learning_rate=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.799808478038815\n",
      "Standard Deviation:  0.0366973248009779\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ada_clf, X, y, cv=10)\n",
    "print(\"mean: \", np.mean(scores))\n",
    "print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy 79.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "        LogisticRegression(), n_estimators=200,\n",
    "        algorithm=\"SAMME.R\", learning_rate=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.7964121552604698\n",
      "Standard Deviation:  0.038679860924303346\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ada_clf, X, y, cv=10)\n",
    "print(\"mean: \", np.mean(scores))\n",
    "print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Accuracy 79.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

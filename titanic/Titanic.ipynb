{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_data = pd.read_csv('./data/train.csv', index_col = 'PassengerId')\n",
    "raw_test_data = pd.read_csv('./data/test.csv', index_col = 'PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = raw_train_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_data = raw_test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name, Ticket, Cabin Feature는 큰 의미가 없을것이라 판단.<br>\n",
    "Column 삭제\n",
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "®삭제하려면 삭제할 수 있는 근거가 있어야 한다.<br>\n",
    "규칙이 없어 보여도 그 안에 무엇인가 있을 수 있음<br><br>\n",
    "\n",
    "여기서 근거를 찾아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | 삭제 이유                                                    |\n",
    "| -------- | ------------------------------------------------------------ |\n",
    "| Name     | *Mrs, Miss, Mr* 가 있으므로 성별과 혼인 여부 알 수 있음.<br> 1. 성별 => **Sex** Feature<br>  2. 혼인한 사람중에 배우자가 같이 동승한 경우 => **Sibsp** Feature<br> 3. 혼인했는데 배우자가 동승하지 않은 경우 => 큰 의미 없다고 판단 |\n",
    "| Ticket <br> Cabin   |  다 고유한 번호들로 느껴져서 안지울 수가 없음            |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null 있는지 확인\n",
    "'Age'에 177개 <br>\n",
    "'Embarked'에 2개 null확인됬음. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(train_data['Age'].isnull().sum())\n",
    "print(train_data['Embarked'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "Fare를 잘 보면 0 값들이 있다(총 15개).<br>\n",
    "이 사람들 무료로 탄걸까?<br>\n",
    "아마 아니겠지. <br>\n",
    "기록이 잘 안된거겠지. <br>\n",
    "이 친구들도 채워 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[train_data.Fare == 0]['Fare'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 히스토그램 그려서 분포를 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noJekxhn0ktQ4g16SGmfQS1Lj/heqruIAbw24BgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd26045eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 100\n",
    "n, bins, patches = plt.hist(train_data['Fare'], num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right Skewed 이 경우에는 Median이 더 Mode에 가까움. <br>\n",
    "Median으로 채우자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_median=train_data.Fare.replace({0: train_data['Fare'].median()})\n",
    "(change_median==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Counts for Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived  Value Counts\n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "---------------------\n",
      "Pclass  Value Counts\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "---------------------\n",
      "Sex  Value Counts\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "---------------------\n",
      "Embarked  Value Counts\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "This Data has 2 null value\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "category_list = ['Survived', 'Pclass', 'Sex', 'Embarked']\n",
    "for i in category_list:\n",
    "    print(i,' Value Counts')\n",
    "    counts = train_data[i].value_counts()\n",
    "    print(counts)\n",
    "    if(counts.sum() != 891):\n",
    "        print('This Data has', 891-counts.sum() ,'null value')\n",
    "    print('---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편향된 데이터가 있는지 체크<br>\n",
    "잘 모르겠음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Pclass'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe for Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.447545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.570235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age       SibSp       Parch        Fare\n",
       "count  714.000000  891.000000  891.000000  891.000000\n",
       "mean    29.699118    0.523008    0.381594   32.447545\n",
       "std     14.526497    1.102743    0.806057   49.570235\n",
       "min      0.420000    0.000000    0.000000    4.012500\n",
       "25%     20.125000    0.000000    0.000000    7.925000\n",
       "50%     28.000000    0.000000    0.000000   14.454200\n",
       "75%     38.000000    1.000000    0.000000   31.000000\n",
       "max     80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[['Age', 'SibSp', 'Parch', 'Fare']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0xd2630a208>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x10b072cc0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0xd265435f8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0xd26187630>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0xd26394400>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0xd263944e0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIgAAANeCAYAAAB57DV/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd261069e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data.hist(bins=50, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.492143</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>-0.577147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.492143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091587</td>\n",
       "      <td>-0.061249</td>\n",
       "      <td>0.337932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.091587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.306895</td>\n",
       "      <td>0.171539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.018721</td>\n",
       "      <td>-0.061249</td>\n",
       "      <td>0.306895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>-0.577147</td>\n",
       "      <td>0.337932</td>\n",
       "      <td>0.171539</td>\n",
       "      <td>0.230046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pclass       Age     SibSp     Parch      Fare\n",
       "Pclass  1.000000 -0.492143  0.001087  0.018721 -0.577147\n",
       "Age    -0.492143  1.000000 -0.091587 -0.061249  0.337932\n",
       "SibSp   0.001087 -0.091587  1.000000  0.306895  0.171539\n",
       "Parch   0.018721 -0.061249  0.306895  1.000000  0.230046\n",
       "Fare   -0.577147  0.337932  0.171539  0.230046  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['Sex'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_1=train_data\n",
    "train_data_1['Sex']=train_data['Sex'].replace({'male':1 ,'female': 2})\n",
    "train_data_1['Embarked']=train_data_1['Embarked'].replace({'C': 1, 'Q':2, 'S':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.254743</td>\n",
       "      <td>-0.169718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.553071</td>\n",
       "      <td>0.164681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.179163</td>\n",
       "      <td>-0.110320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.097207</td>\n",
       "      <td>-0.032565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.157717</td>\n",
       "      <td>0.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>0.040449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.254743</td>\n",
       "      <td>-0.553071</td>\n",
       "      <td>0.179163</td>\n",
       "      <td>0.097207</td>\n",
       "      <td>0.157717</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.223984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.169718</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.223984</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Sex       Age     SibSp     Parch  \\\n",
       "Survived  1.000000 -0.338481  0.543351 -0.077221 -0.035322  0.081629   \n",
       "Pclass   -0.338481  1.000000 -0.131900 -0.369226  0.083081  0.018443   \n",
       "Sex       0.543351 -0.131900  1.000000 -0.093254  0.114631  0.245489   \n",
       "Age      -0.077221 -0.369226 -0.093254  1.000000 -0.308247 -0.189119   \n",
       "SibSp    -0.035322  0.083081  0.114631 -0.308247  1.000000  0.414838   \n",
       "Parch     0.081629  0.018443  0.245489 -0.189119  0.414838  1.000000   \n",
       "Fare      0.254743 -0.553071  0.179163  0.097207  0.157717  0.214436   \n",
       "Embarked -0.169718  0.164681 -0.110320 -0.032565  0.068900  0.040449   \n",
       "\n",
       "              Fare  Embarked  \n",
       "Survived  0.254743 -0.169718  \n",
       "Pclass   -0.553071  0.164681  \n",
       "Sex       0.179163 -0.110320  \n",
       "Age       0.097207 -0.032565  \n",
       "SibSp     0.157717  0.068900  \n",
       "Parch     0.214436  0.040449  \n",
       "Fare      1.000000 -0.223984  \n",
       "Embarked -0.223984  1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "Correlation은 Continuous Value를 전제로 한다.<br>\n",
    "Correlation을 계산해서 의미가 있으면 감을 잡을 순 있지만.<br>\n",
    "그것을 어떤 *'객관적 근거'*로서 활용하기 에는 무리가 있다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재<br>\n",
    "'Survived', 'Pclass', 'Sex', 'Embarked' -> Categorical <br>\n",
    "'Age', 'SibSp', 'Parch', 'Fare' -> Numerical But Discrete Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어쨋든 Correlation 이 Sex와 Pclass가 높긴 해."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "1. ***Correlation 은 Discrete일때도 객관적 근거가 될 수 없을까?***<br>\n",
    "2. ***그럼 뭐가 객관적 근거가 되는 걸까?***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1379</td>\n",
       "      <td>13919.17</td>\n",
       "      <td>248</td>\n",
       "      <td>136</td>\n",
       "      <td>14944.0995</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>233</td>\n",
       "      <td>678</td>\n",
       "      <td>7286.00</td>\n",
       "      <td>218</td>\n",
       "      <td>204</td>\n",
       "      <td>13966.6628</td>\n",
       "      <td>754.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass       Age  SibSp  Parch        Fare  Embarked\n",
       "Sex                                                                \n",
       "1         109    1379  13919.17    248    136  14944.0995    1500.0\n",
       "2         233     678   7286.00    218    204  13966.6628     754.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Sex').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "      <td>453</td>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>261</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Age  SibSp  Parch  Fare  Embarked\n",
       "Sex                                                     \n",
       "1         577     577  453    577    577   577       577\n",
       "2         314     314  261    314    314   314       312"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of non-null observations\n",
    "train_data.groupby('Sex').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight 1** \n",
    "여자는 대부분 살고 남자는 대부분 죽었음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    0.629630\n",
       "2    0.472826\n",
       "3    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Pclass').sum()['Survived'] / train_data.groupby('Pclass').count()['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight 2** \n",
    "1등석이 확실히 더 많이 살았음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "1.0    0.553571\n",
       "2.0    0.389610\n",
       "3.0    0.336957\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Embarked').sum()['Survived'] / train_data.groupby('Embarked').count()['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight 3** \n",
    "Cherbourg에서 승선한 사람은 50% 넘게 살았음 <br>\n",
    "출구 쪽에 있었나?<br>\n",
    "혹시 가장 마지막에 탑승했거나, 비상구에서 가까운 쪽에 위치하고 있었나?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SibSp\n",
      "0    0.345395\n",
      "1    0.535885\n",
      "2    0.464286\n",
      "3    0.250000\n",
      "4    0.166667\n",
      "5    0.000000\n",
      "8    0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Parch\n",
      "0    0.343658\n",
      "1    0.550847\n",
      "2    0.500000\n",
      "3    0.600000\n",
      "4    0.000000\n",
      "5    0.200000\n",
      "6    0.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.groupby('SibSp').sum()['Survived'] / train_data.groupby('SibSp').count()['Survived'])\n",
    "print(train_data.groupby('Parch').sum()['Survived'] / train_data.groupby('Parch').count()['Survived'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이건 딱히 얻을게 있는지 잘 모르겠다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>1.352413</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.447545</td>\n",
       "      <td>2.535433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.570235</td>\n",
       "      <td>0.792088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.012500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Sex         Age       SibSp       Parch  \\\n",
       "count  891.000000  891.000000  891.000000  714.000000  891.000000  891.000000   \n",
       "mean     0.383838    2.308642    1.352413   29.699118    0.523008    0.381594   \n",
       "std      0.486592    0.836071    0.477990   14.526497    1.102743    0.806057   \n",
       "min      0.000000    1.000000    1.000000    0.420000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000    1.000000   20.125000    0.000000    0.000000   \n",
       "50%      0.000000    3.000000    1.000000   28.000000    0.000000    0.000000   \n",
       "75%      1.000000    3.000000    2.000000   38.000000    1.000000    0.000000   \n",
       "max      1.000000    3.000000    2.000000   80.000000    8.000000    6.000000   \n",
       "\n",
       "             Fare    Embarked  \n",
       "count  891.000000  889.000000  \n",
       "mean    32.447545    2.535433  \n",
       "std     49.570235    0.792088  \n",
       "min      4.012500    1.000000  \n",
       "25%      7.925000    2.000000  \n",
       "50%     14.454200    3.000000  \n",
       "75%     31.000000    3.000000  \n",
       "max    512.329200    3.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [x for x in range(-1, 81, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "labels = [x for x in range(0, 8)]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "향후 New Features로 활용하게 편하게 <br>\n",
    "0~9세: 0, 10~19세 : 1 <br>\n",
    "이런식으로 세대 별로 매핑해서 Categorical Data로 만들었음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked  \\\n",
       "PassengerId                                                                  \n",
       "1                   0       3    1  22.0      1      0    7.2500       3.0   \n",
       "2                   1       1    2  38.0      1      0   71.2833       1.0   \n",
       "3                   1       3    2  26.0      0      0    7.9250       3.0   \n",
       "4                   1       1    2  35.0      1      0   53.1000       3.0   \n",
       "5                   0       3    1  35.0      0      0    8.0500       3.0   \n",
       "6                   0       3    1   NaN      0      0    8.4583       2.0   \n",
       "7                   0       1    1  54.0      0      0   51.8625       3.0   \n",
       "8                   0       3    1   2.0      3      1   21.0750       3.0   \n",
       "9                   1       3    2  27.0      0      2   11.1333       3.0   \n",
       "10                  1       2    2  14.0      1      0   30.0708       1.0   \n",
       "11                  1       3    2   4.0      1      1   16.7000       3.0   \n",
       "12                  1       1    2  58.0      0      0   26.5500       3.0   \n",
       "13                  0       3    1  20.0      0      0    8.0500       3.0   \n",
       "14                  0       3    1  39.0      1      5   31.2750       3.0   \n",
       "15                  0       3    2  14.0      0      0    7.8542       3.0   \n",
       "16                  1       2    2  55.0      0      0   16.0000       3.0   \n",
       "17                  0       3    1   2.0      4      1   29.1250       2.0   \n",
       "18                  1       2    1   NaN      0      0   13.0000       3.0   \n",
       "19                  0       3    2  31.0      1      0   18.0000       3.0   \n",
       "20                  1       3    2   NaN      0      0    7.2250       1.0   \n",
       "21                  0       2    1  35.0      0      0   26.0000       3.0   \n",
       "22                  1       2    1  34.0      0      0   13.0000       3.0   \n",
       "23                  1       3    2  15.0      0      0    8.0292       2.0   \n",
       "24                  1       1    1  28.0      0      0   35.5000       3.0   \n",
       "25                  0       3    2   8.0      3      1   21.0750       3.0   \n",
       "26                  1       3    2  38.0      1      5   31.3875       3.0   \n",
       "27                  0       3    1   NaN      0      0    7.2250       1.0   \n",
       "28                  0       1    1  19.0      3      2  263.0000       3.0   \n",
       "29                  1       3    2   NaN      0      0    7.8792       2.0   \n",
       "30                  0       3    1   NaN      0      0    7.8958       3.0   \n",
       "...               ...     ...  ...   ...    ...    ...       ...       ...   \n",
       "862                 0       2    1  21.0      1      0   11.5000       3.0   \n",
       "863                 1       1    2  48.0      0      0   25.9292       3.0   \n",
       "864                 0       3    2   NaN      8      2   69.5500       3.0   \n",
       "865                 0       2    1  24.0      0      0   13.0000       3.0   \n",
       "866                 1       2    2  42.0      0      0   13.0000       3.0   \n",
       "867                 1       2    2  27.0      1      0   13.8583       1.0   \n",
       "868                 0       1    1  31.0      0      0   50.4958       3.0   \n",
       "869                 0       3    1   NaN      0      0    9.5000       3.0   \n",
       "870                 1       3    1   4.0      1      1   11.1333       3.0   \n",
       "871                 0       3    1  26.0      0      0    7.8958       3.0   \n",
       "872                 1       1    2  47.0      1      1   52.5542       3.0   \n",
       "873                 0       1    1  33.0      0      0    5.0000       3.0   \n",
       "874                 0       3    1  47.0      0      0    9.0000       3.0   \n",
       "875                 1       2    2  28.0      1      0   24.0000       1.0   \n",
       "876                 1       3    2  15.0      0      0    7.2250       1.0   \n",
       "877                 0       3    1  20.0      0      0    9.8458       3.0   \n",
       "878                 0       3    1  19.0      0      0    7.8958       3.0   \n",
       "879                 0       3    1   NaN      0      0    7.8958       3.0   \n",
       "880                 1       1    2  56.0      0      1   83.1583       1.0   \n",
       "881                 1       2    2  25.0      0      1   26.0000       3.0   \n",
       "882                 0       3    1  33.0      0      0    7.8958       3.0   \n",
       "883                 0       3    2  22.0      0      0   10.5167       3.0   \n",
       "884                 0       2    1  28.0      0      0   10.5000       3.0   \n",
       "885                 0       3    1  25.0      0      0    7.0500       3.0   \n",
       "886                 0       3    2  39.0      0      5   29.1250       2.0   \n",
       "887                 0       2    1  27.0      0      0   13.0000       3.0   \n",
       "888                 1       1    2  19.0      0      0   30.0000       3.0   \n",
       "889                 0       3    2   NaN      1      2   23.4500       3.0   \n",
       "890                 1       1    1  26.0      0      0   30.0000       1.0   \n",
       "891                 0       3    1  32.0      0      0    7.7500       2.0   \n",
       "\n",
       "            Age_Cut  \n",
       "PassengerId          \n",
       "1               2.0  \n",
       "2               3.0  \n",
       "3               2.0  \n",
       "4               3.0  \n",
       "5               3.0  \n",
       "6               NaN  \n",
       "7               5.0  \n",
       "8               0.0  \n",
       "9               2.0  \n",
       "10              1.0  \n",
       "11              0.0  \n",
       "12              5.0  \n",
       "13              2.0  \n",
       "14              3.0  \n",
       "15              1.0  \n",
       "16              5.0  \n",
       "17              0.0  \n",
       "18              NaN  \n",
       "19              3.0  \n",
       "20              NaN  \n",
       "21              3.0  \n",
       "22              3.0  \n",
       "23              1.0  \n",
       "24              2.0  \n",
       "25              0.0  \n",
       "26              3.0  \n",
       "27              NaN  \n",
       "28              1.0  \n",
       "29              NaN  \n",
       "30              NaN  \n",
       "...             ...  \n",
       "862             2.0  \n",
       "863             4.0  \n",
       "864             NaN  \n",
       "865             2.0  \n",
       "866             4.0  \n",
       "867             2.0  \n",
       "868             3.0  \n",
       "869             NaN  \n",
       "870             0.0  \n",
       "871             2.0  \n",
       "872             4.0  \n",
       "873             3.0  \n",
       "874             4.0  \n",
       "875             2.0  \n",
       "876             1.0  \n",
       "877             2.0  \n",
       "878             1.0  \n",
       "879             NaN  \n",
       "880             5.0  \n",
       "881             2.0  \n",
       "882             3.0  \n",
       "883             2.0  \n",
       "884             2.0  \n",
       "885             2.0  \n",
       "886             3.0  \n",
       "887             2.0  \n",
       "888             1.0  \n",
       "889             NaN  \n",
       "890             2.0  \n",
       "891             3.0  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_ages = train_data.copy()\n",
    "train_data_with_ages['Age_Cut'] = pd.cut(train_data_with_ages['Age'], labels=labels,\n",
    "                              bins=bins, include_lowest = True)\n",
    "train_data_with_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut\n",
      "0    0.612903\n",
      "1    0.401961\n",
      "2    0.350000\n",
      "3    0.437126\n",
      "4    0.382022\n",
      "5    0.416667\n",
      "6    0.315789\n",
      "7    0.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_ages.groupby('Age_Cut').sum()['Survived'] / train_data_with_ages.groupby('Age_Cut').count()['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**나이대 별로 보면** 애기들이 확실히 더 많이 살았으니깐 <br>\n",
    "이 상태로 다시 Correlation 체크 하자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_cut = train_data_with_ages.Age_Cut.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_with_ages['Age_Cut']=int_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.254743</td>\n",
       "      <td>-0.169718</td>\n",
       "      <td>-0.080072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.553071</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.349140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.179163</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.090459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.097207</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.980262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.157717</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>-0.300555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.188898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.254743</td>\n",
       "      <td>-0.553071</td>\n",
       "      <td>0.179163</td>\n",
       "      <td>0.097207</td>\n",
       "      <td>0.157717</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.223984</td>\n",
       "      <td>0.091475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.169718</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.223984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Cut</th>\n",
       "      <td>-0.080072</td>\n",
       "      <td>-0.349140</td>\n",
       "      <td>-0.090459</td>\n",
       "      <td>0.980262</td>\n",
       "      <td>-0.300555</td>\n",
       "      <td>-0.188898</td>\n",
       "      <td>0.091475</td>\n",
       "      <td>-0.040965</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Sex       Age     SibSp     Parch  \\\n",
       "Survived  1.000000 -0.338481  0.543351 -0.077221 -0.035322  0.081629   \n",
       "Pclass   -0.338481  1.000000 -0.131900 -0.369226  0.083081  0.018443   \n",
       "Sex       0.543351 -0.131900  1.000000 -0.093254  0.114631  0.245489   \n",
       "Age      -0.077221 -0.369226 -0.093254  1.000000 -0.308247 -0.189119   \n",
       "SibSp    -0.035322  0.083081  0.114631 -0.308247  1.000000  0.414838   \n",
       "Parch     0.081629  0.018443  0.245489 -0.189119  0.414838  1.000000   \n",
       "Fare      0.254743 -0.553071  0.179163  0.097207  0.157717  0.214436   \n",
       "Embarked -0.169718  0.164681 -0.110320 -0.032565  0.068900  0.040449   \n",
       "Age_Cut  -0.080072 -0.349140 -0.090459  0.980262 -0.300555 -0.188898   \n",
       "\n",
       "              Fare  Embarked   Age_Cut  \n",
       "Survived  0.254743 -0.169718 -0.080072  \n",
       "Pclass   -0.553071  0.164681 -0.349140  \n",
       "Sex       0.179163 -0.110320 -0.090459  \n",
       "Age       0.097207 -0.032565  0.980262  \n",
       "SibSp     0.157717  0.068900 -0.300555  \n",
       "Parch     0.214436  0.040449 -0.188898  \n",
       "Fare      1.000000 -0.223984  0.091475  \n",
       "Embarked -0.223984  1.000000 -0.040965  \n",
       "Age_Cut   0.091475 -0.040965  1.000000  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_ages.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut\n",
      "0.0    0.612903\n",
      "1.0    0.401961\n",
      "2.0    0.350000\n",
      "3.0    0.437126\n",
      "4.0    0.382022\n",
      "5.0    0.416667\n",
      "6.0    0.315789\n",
      "7.0    0.000000\n",
      "Name: Survived, dtype: float64\n",
      "SibSp\n",
      "0    0.345395\n",
      "1    0.535885\n",
      "2    0.464286\n",
      "3    0.250000\n",
      "4    0.166667\n",
      "5    0.000000\n",
      "8    0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Parch\n",
      "0    0.343658\n",
      "1    0.550847\n",
      "2    0.500000\n",
      "3    0.600000\n",
      "4    0.000000\n",
      "5    0.200000\n",
      "6    0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Embarked\n",
      "1.0    0.553571\n",
      "2.0    0.389610\n",
      "3.0    0.336957\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_ages.groupby('Age_Cut').sum()['Survived'] / train_data_with_ages.groupby('Age_Cut').count()['Survived'])\n",
    "print(train_data_with_ages.groupby('SibSp').sum()['Survived'] / train_data_with_ages.groupby('SibSp').count()['Survived'])\n",
    "print(train_data_with_ages.groupby('Parch').sum()['Survived'] / train_data_with_ages.groupby('Parch').count()['Survived'])\n",
    "print(train_data_with_ages.groupby('Embarked').sum()['Survived'] / train_data_with_ages.groupby('Embarked').count()['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "확실히 Corrr값도 높게 나오는건, Pclass와 Sex<br>\n",
    "그러나 Corr이 객관적 근거가 될 수 없다는 것  <=> Corr 이외 에도 객관적으로 유의한 지표들이 있을 수 있다는 것 <br>\n",
    "Categorical데이터에 대해 추가적으로 찾아보면 <br>\n",
    "***Age_Cut : 어린애들 많이 살았고,***<br>\n",
    "***Embarked: 특정 위치에서 승선한 사람이 에서 더 많이 삼***<br>\n",
    "조금 있다가 묶어서 더 분석 해보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1차적으로 가장 중요한 Feature는 Sex, Pclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex  Pclass\n",
       "1    1         0.368852\n",
       "     2         0.157407\n",
       "     3         0.135447\n",
       "2    1         0.968085\n",
       "     2         0.921053\n",
       "     3         0.500000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Sex', 'Pclass']).sum()['Survived'] / train_data.groupby(['Sex', 'Pclass']).count()['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Sex\n",
       "1       1      0.368852\n",
       "        2      0.968085\n",
       "2       1      0.157407\n",
       "        2      0.921053\n",
       "3       1      0.135447\n",
       "        2      0.500000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Pclass', 'Sex']).sum()['Survived'] / train_data.groupby(['Pclass', 'Sex']).count()['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 여자가 Sex 2번, <br>\n",
    "***여자 + 1등석 96.8% 생존***<br>\n",
    "***여자 + 2등석 92.1% 생존***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pclass_sex = train_data.groupby(['Pclass', 'Sex']).sum()['Survived'] / train_data.groupby(['Pclass', 'Sex']).count()['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_groups = 3\n",
    "women_survived = []\n",
    "men_survived= []\n",
    "for i in range(1, 4):\n",
    "    men_survived.append(pclass_sex[i][1])\n",
    "    women_survived.append(pclass_sex[i][2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZlZIf1/PV1KW7BihmcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd26bdc748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.7\n",
    " \n",
    "rects1 = plt.bar(index, men_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='Men')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, women_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='Women')\n",
    " \n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Survived(%)')\n",
    "plt.title('Survived People sorted by PClass')\n",
    "plt.xticks(index + bar_width, ('1st Class', '2nd Class', '3rd Class'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sex_pclass= train_data.groupby(['Sex', 'Pclass']).sum()['Survived'] / train_data.groupby(['Sex', 'Pclass']).count()['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex  Pclass\n",
       "1    1         0.368852\n",
       "     2         0.157407\n",
       "     3         0.135447\n",
       "2    1         0.968085\n",
       "     2         0.921053\n",
       "     3         0.500000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sex_list = ['male', 'female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_groups = 2\n",
    "first_survived = []\n",
    "second_survived= []\n",
    "third_survived =[]\n",
    "for i in [1, 2]:\n",
    "    first_survived.append(sex_pclass[i][1])\n",
    "    second_survived.append(sex_pclass[i][2])\n",
    "    third_survived.append(sex_pclass[i][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noMzMLJMcUGZmlkn/H9zpx1SiKXeZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd26b81e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.15\n",
    "opacity = 0.7\n",
    " \n",
    "rects1 = plt.bar(index, first_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='1st Survived')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, second_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='2nd Survived')\n",
    "rects3 = plt.bar(index + bar_width+bar_width, third_survived, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='3rd Survived')\n",
    "\n",
    " \n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Survived')\n",
    "plt.title('Survived People sorted by Sex')\n",
    "plt.xticks(index + bar_width, ('Men', 'Women'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 새로운 Feature 만들어 보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 Pclass와 Sex를 기본으로<br>\n",
    "아까 의심이 됬던 Age와 더불어 여러가지를 상상력으로 조합해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_with_new_features = train_data_with_ages.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.254743</td>\n",
       "      <td>-0.169718</td>\n",
       "      <td>-0.080072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.553071</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.349140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.179163</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.090459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.097207</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.980262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.157717</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>-0.300555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.188898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.254743</td>\n",
       "      <td>-0.553071</td>\n",
       "      <td>0.179163</td>\n",
       "      <td>0.097207</td>\n",
       "      <td>0.157717</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.223984</td>\n",
       "      <td>0.091475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.169718</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.223984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Cut</th>\n",
       "      <td>-0.080072</td>\n",
       "      <td>-0.349140</td>\n",
       "      <td>-0.090459</td>\n",
       "      <td>0.980262</td>\n",
       "      <td>-0.300555</td>\n",
       "      <td>-0.188898</td>\n",
       "      <td>0.091475</td>\n",
       "      <td>-0.040965</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Sex       Age     SibSp     Parch  \\\n",
       "Survived  1.000000 -0.338481  0.543351 -0.077221 -0.035322  0.081629   \n",
       "Pclass   -0.338481  1.000000 -0.131900 -0.369226  0.083081  0.018443   \n",
       "Sex       0.543351 -0.131900  1.000000 -0.093254  0.114631  0.245489   \n",
       "Age      -0.077221 -0.369226 -0.093254  1.000000 -0.308247 -0.189119   \n",
       "SibSp    -0.035322  0.083081  0.114631 -0.308247  1.000000  0.414838   \n",
       "Parch     0.081629  0.018443  0.245489 -0.189119  0.414838  1.000000   \n",
       "Fare      0.254743 -0.553071  0.179163  0.097207  0.157717  0.214436   \n",
       "Embarked -0.169718  0.164681 -0.110320 -0.032565  0.068900  0.040449   \n",
       "Age_Cut  -0.080072 -0.349140 -0.090459  0.980262 -0.300555 -0.188898   \n",
       "\n",
       "              Fare  Embarked   Age_Cut  \n",
       "Survived  0.254743 -0.169718 -0.080072  \n",
       "Pclass   -0.553071  0.164681 -0.349140  \n",
       "Sex       0.179163 -0.110320 -0.090459  \n",
       "Age       0.097207 -0.032565  0.980262  \n",
       "SibSp     0.157717  0.068900 -0.300555  \n",
       "Parch     0.214436  0.040449 -0.188898  \n",
       "Fare      1.000000 -0.223984  0.091475  \n",
       "Embarked -0.223984  1.000000 -0.040965  \n",
       "Age_Cut   0.091475 -0.040965  1.000000  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_ages.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex  SibSp\n",
      "1    0         73\n",
      "     1         32\n",
      "     2          3\n",
      "     3          0\n",
      "     4          1\n",
      "     5          0\n",
      "     8          0\n",
      "2    0        137\n",
      "     1         80\n",
      "     2         10\n",
      "     3          4\n",
      "     4          2\n",
      "     5          0\n",
      "     8          0\n",
      "Name: Survived, dtype: int64\n",
      "Sex  SibSp\n",
      "1    0        434\n",
      "     1        103\n",
      "     2         15\n",
      "     3          5\n",
      "     4         12\n",
      "     5          4\n",
      "     8          4\n",
      "2    0        174\n",
      "     1        106\n",
      "     2         13\n",
      "     3         11\n",
      "     4          6\n",
      "     5          1\n",
      "     8          3\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_new_features.groupby(['Sex','SibSp']).sum()['Survived'])\n",
    "print(train_data_with_new_features.groupby(['Sex','SibSp']).count()['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut  Parch\n",
      "0.0      0          1\n",
      "         1         35\n",
      "         2         26\n",
      "1.0      0         71\n",
      "         1         15\n",
      "         2         15\n",
      "         3          1\n",
      "2.0      0        187\n",
      "         1         15\n",
      "         2         15\n",
      "         3          2\n",
      "         4          1\n",
      "3.0      0        136\n",
      "         1         19\n",
      "         2          8\n",
      "         5          4\n",
      "4.0      0         67\n",
      "         1         14\n",
      "         2          3\n",
      "         3          1\n",
      "         4          2\n",
      "         5          1\n",
      "         6          1\n",
      "5.0      0         38\n",
      "         1          8\n",
      "         2          1\n",
      "         3          1\n",
      "6.0      0         15\n",
      "         1          3\n",
      "         4          1\n",
      "7.0      0          5\n",
      "         1          1\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_new_features.groupby(['Age_Cut', 'Parch']).count()['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut  Parch\n",
      "0.0      0        1.000000\n",
      "         1        0.657143\n",
      "         2        0.538462\n",
      "1.0      0        0.380282\n",
      "         1        0.400000\n",
      "         2        0.533333\n",
      "         3        0.000000\n",
      "2.0      0        0.304813\n",
      "         1        0.533333\n",
      "         2        0.666667\n",
      "         3        1.000000\n",
      "         4        0.000000\n",
      "3.0      0        0.411765\n",
      "         1        0.526316\n",
      "         2        0.750000\n",
      "         5        0.250000\n",
      "4.0      0        0.373134\n",
      "         1        0.571429\n",
      "         2        0.333333\n",
      "         3        0.000000\n",
      "         4        0.000000\n",
      "         5        0.000000\n",
      "         6        0.000000\n",
      "5.0      0        0.368421\n",
      "         1        0.625000\n",
      "         2        0.000000\n",
      "         3        1.000000\n",
      "6.0      0        0.333333\n",
      "         1        0.333333\n",
      "         4        0.000000\n",
      "7.0      0        0.000000\n",
      "         1        0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Parch  Age_Cut\n",
      "0      0.0        1.000000\n",
      "       1.0        0.380282\n",
      "       2.0        0.304813\n",
      "       3.0        0.411765\n",
      "       4.0        0.373134\n",
      "       5.0        0.368421\n",
      "       6.0        0.333333\n",
      "       7.0        0.000000\n",
      "1      0.0        0.657143\n",
      "       1.0        0.400000\n",
      "       2.0        0.533333\n",
      "       3.0        0.526316\n",
      "       4.0        0.571429\n",
      "       5.0        0.625000\n",
      "       6.0        0.333333\n",
      "       7.0        0.000000\n",
      "2      0.0        0.538462\n",
      "       1.0        0.533333\n",
      "       2.0        0.666667\n",
      "       3.0        0.750000\n",
      "       4.0        0.333333\n",
      "       5.0        0.000000\n",
      "3      1.0        0.000000\n",
      "       2.0        1.000000\n",
      "       4.0        0.000000\n",
      "       5.0        1.000000\n",
      "4      2.0        0.000000\n",
      "       4.0        0.000000\n",
      "       6.0        0.000000\n",
      "5      3.0        0.250000\n",
      "       4.0        0.000000\n",
      "6      4.0        0.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_new_features.groupby(['Age_Cut','Parch']).sum()['Survived'] / train_data_with_new_features.groupby(['Age_Cut','Parch']).count()['Survived'])\n",
    "print(train_data_with_new_features.groupby(['Parch','Age_Cut']).sum()['Survived'] / train_data_with_new_features.groupby(['Parch','Age_Cut']).count()['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아니 근데 0~9세중에 Parch가 0인 1명은 대체 뭐지?<br>\n",
    "근데 또 어떻게 다 살았지?<br>\n",
    "지금 부모가 있는 자녀들이 더 많이 산건가?<br>\n",
    "그걸 잘 모르겠음.<br>\n",
    "근데 생각해보니깐 **꼬마들은 다 부모 있는거 아닌가?<br>\n",
    "그럼 그게 0~9세 + Parch > 0 이 유의미한 변수라고 보기 힘들지 않나?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked  Sex\n",
       "1.0       1      0.305263\n",
       "          2      0.876712\n",
       "2.0       1      0.073171\n",
       "          2      0.750000\n",
       "3.0       1      0.174603\n",
       "          2      0.689655\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_new_features.groupby(['Sex','Pclass','Age_Cut']).sum()['Survived'] / train_data_with_new_features.groupby(['Sex','Pclass','Age_Cut']).count()['Survived']\n",
    "train_data_with_new_features.groupby(['Embarked','Sex']).sum()['Survived'] / train_data_with_new_features.groupby(['Embarked','Sex']).count()['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Cut  Sex\n",
      "0.0      1      0.593750\n",
      "         2      0.633333\n",
      "1.0      1      0.122807\n",
      "         2      0.755556\n",
      "2.0      1      0.168919\n",
      "         2      0.722222\n",
      "3.0      1      0.214953\n",
      "         2      0.833333\n",
      "4.0      1      0.210526\n",
      "         2      0.687500\n",
      "5.0      1      0.133333\n",
      "         2      0.888889\n",
      "6.0      1      0.133333\n",
      "         2      1.000000\n",
      "7.0      1      0.000000\n",
      "Name: Survived, dtype: float64\n",
      "Sex  Age_Cut\n",
      "1    0.0        0.593750\n",
      "     1.0        0.122807\n",
      "     2.0        0.168919\n",
      "     3.0        0.214953\n",
      "     4.0        0.210526\n",
      "     5.0        0.133333\n",
      "     6.0        0.133333\n",
      "     7.0        0.000000\n",
      "2    0.0        0.633333\n",
      "     1.0        0.755556\n",
      "     2.0        0.722222\n",
      "     3.0        0.833333\n",
      "     4.0        0.687500\n",
      "     5.0        0.888889\n",
      "     6.0        1.000000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_new_features.groupby(['Age_Cut','Sex']).sum()['Survived'] / train_data_with_new_features.groupby(['Age_Cut','Sex']).count()['Survived']\n",
    "     )\n",
    "print(train_data_with_new_features.groupby(['Sex','Age_Cut']).sum()['Survived'] / train_data_with_new_features.groupby(['Sex','Age_Cut']).count()['Survived']\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상상력이 없나...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagination\n",
    "\n",
    "1. 여자면서 1st Class면 다 살았다고 해도 96%는 맞아(여자+2nd class도 92%는 맞아).\n",
    "2. 일단 70대는 죽었다고 판단해도 될거 같아. → 구조원칙 상으로도 애기들부터 살린다네(근데 여자는 70대가 없음. 근데 50~60대가 거의 다삼. 쓰기 어려울듯)\n",
    "3. 여자는 나이 대 별로 차이도 많이 안나고, 심지어 50~60대 여자들이 엄청나게 살았는데 남자는 \n",
    "    나이대 까지 상관없이 그냥 거의 다 죽음\n",
    "\n",
    "4. 남편이 같이 탄 여자? -> 찾아봤는데 딱히...\n",
    "5. 부모 혹은 자녀가 있는 사람? → 찾아봤는데 딱히...\n",
    "\n",
    "\n",
    "**여자 + 1st, 2nd Class라도 해서 하나 만들자**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_pclass_mask =(train_data_with_new_features['Sex']==2) & (train_data_with_new_features.Pclass !=  3) \n",
    "train_data_with_new_features['women_1st_2nd_class']=sex_pclass_mask.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.254743</td>\n",
       "      <td>-0.169718</td>\n",
       "      <td>-0.080072</td>\n",
       "      <td>0.562359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.553071</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.349140</td>\n",
       "      <td>-0.500673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.179163</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.090459</td>\n",
       "      <td>0.658233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>-0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.097207</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.980262</td>\n",
       "      <td>0.080084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.157717</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>-0.300555</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.188898</td>\n",
       "      <td>0.085551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.254743</td>\n",
       "      <td>-0.553071</td>\n",
       "      <td>0.179163</td>\n",
       "      <td>0.097207</td>\n",
       "      <td>0.157717</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.223984</td>\n",
       "      <td>0.091475</td>\n",
       "      <td>0.353390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.169718</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>-0.223984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040965</td>\n",
       "      <td>-0.090566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Cut</th>\n",
       "      <td>-0.080072</td>\n",
       "      <td>-0.349140</td>\n",
       "      <td>-0.090459</td>\n",
       "      <td>0.980262</td>\n",
       "      <td>-0.300555</td>\n",
       "      <td>-0.188898</td>\n",
       "      <td>0.091475</td>\n",
       "      <td>-0.040965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "      <td>0.562359</td>\n",
       "      <td>-0.500673</td>\n",
       "      <td>0.658233</td>\n",
       "      <td>0.080084</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.085551</td>\n",
       "      <td>0.353390</td>\n",
       "      <td>-0.090566</td>\n",
       "      <td>0.078868</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Survived    Pclass       Sex       Age     SibSp  \\\n",
       "Survived             1.000000 -0.338481  0.543351 -0.077221 -0.035322   \n",
       "Pclass              -0.338481  1.000000 -0.131900 -0.369226  0.083081   \n",
       "Sex                  0.543351 -0.131900  1.000000 -0.093254  0.114631   \n",
       "Age                 -0.077221 -0.369226 -0.093254  1.000000 -0.308247   \n",
       "SibSp               -0.035322  0.083081  0.114631 -0.308247  1.000000   \n",
       "Parch                0.081629  0.018443  0.245489 -0.189119  0.414838   \n",
       "Fare                 0.254743 -0.553071  0.179163  0.097207  0.157717   \n",
       "Embarked            -0.169718  0.164681 -0.110320 -0.032565  0.068900   \n",
       "Age_Cut             -0.080072 -0.349140 -0.090459  0.980262 -0.300555   \n",
       "women_1st_2nd_class  0.562359 -0.500673  0.658233  0.080084  0.000230   \n",
       "\n",
       "                        Parch      Fare  Embarked   Age_Cut  \\\n",
       "Survived             0.081629  0.254743 -0.169718 -0.080072   \n",
       "Pclass               0.018443 -0.553071  0.164681 -0.349140   \n",
       "Sex                  0.245489  0.179163 -0.110320 -0.090459   \n",
       "Age                 -0.189119  0.097207 -0.032565  0.980262   \n",
       "SibSp                0.414838  0.157717  0.068900 -0.300555   \n",
       "Parch                1.000000  0.214436  0.040449 -0.188898   \n",
       "Fare                 0.214436  1.000000 -0.223984  0.091475   \n",
       "Embarked             0.040449 -0.223984  1.000000 -0.040965   \n",
       "Age_Cut             -0.188898  0.091475 -0.040965  1.000000   \n",
       "women_1st_2nd_class  0.085551  0.353390 -0.090566  0.078868   \n",
       "\n",
       "                     women_1st_2nd_class  \n",
       "Survived                        0.562359  \n",
       "Pclass                         -0.500673  \n",
       "Sex                             0.658233  \n",
       "Age                             0.080084  \n",
       "SibSp                           0.000230  \n",
       "Parch                           0.085551  \n",
       "Fare                            0.353390  \n",
       "Embarked                       -0.090566  \n",
       "Age_Cut                         0.078868  \n",
       "women_1st_2nd_class             1.000000  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_new_features.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "1. ***근데 만들었어도 어떻게 객관적으로 확인하지? 지금처럼 하면 되나?***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재까지! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_Cut</th>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked  \\\n",
       "PassengerId                                                                  \n",
       "1                   0       3    1  22.0      1      0    7.2500       3.0   \n",
       "2                   1       1    2  38.0      1      0   71.2833       1.0   \n",
       "3                   1       3    2  26.0      0      0    7.9250       3.0   \n",
       "4                   1       1    2  35.0      1      0   53.1000       3.0   \n",
       "5                   0       3    1  35.0      0      0    8.0500       3.0   \n",
       "6                   0       3    1   NaN      0      0    8.4583       2.0   \n",
       "7                   0       1    1  54.0      0      0   51.8625       3.0   \n",
       "8                   0       3    1   2.0      3      1   21.0750       3.0   \n",
       "9                   1       3    2  27.0      0      2   11.1333       3.0   \n",
       "10                  1       2    2  14.0      1      0   30.0708       1.0   \n",
       "11                  1       3    2   4.0      1      1   16.7000       3.0   \n",
       "12                  1       1    2  58.0      0      0   26.5500       3.0   \n",
       "13                  0       3    1  20.0      0      0    8.0500       3.0   \n",
       "14                  0       3    1  39.0      1      5   31.2750       3.0   \n",
       "15                  0       3    2  14.0      0      0    7.8542       3.0   \n",
       "16                  1       2    2  55.0      0      0   16.0000       3.0   \n",
       "17                  0       3    1   2.0      4      1   29.1250       2.0   \n",
       "18                  1       2    1   NaN      0      0   13.0000       3.0   \n",
       "19                  0       3    2  31.0      1      0   18.0000       3.0   \n",
       "20                  1       3    2   NaN      0      0    7.2250       1.0   \n",
       "21                  0       2    1  35.0      0      0   26.0000       3.0   \n",
       "22                  1       2    1  34.0      0      0   13.0000       3.0   \n",
       "23                  1       3    2  15.0      0      0    8.0292       2.0   \n",
       "24                  1       1    1  28.0      0      0   35.5000       3.0   \n",
       "25                  0       3    2   8.0      3      1   21.0750       3.0   \n",
       "26                  1       3    2  38.0      1      5   31.3875       3.0   \n",
       "27                  0       3    1   NaN      0      0    7.2250       1.0   \n",
       "28                  0       1    1  19.0      3      2  263.0000       3.0   \n",
       "29                  1       3    2   NaN      0      0    7.8792       2.0   \n",
       "30                  0       3    1   NaN      0      0    7.8958       3.0   \n",
       "...               ...     ...  ...   ...    ...    ...       ...       ...   \n",
       "862                 0       2    1  21.0      1      0   11.5000       3.0   \n",
       "863                 1       1    2  48.0      0      0   25.9292       3.0   \n",
       "864                 0       3    2   NaN      8      2   69.5500       3.0   \n",
       "865                 0       2    1  24.0      0      0   13.0000       3.0   \n",
       "866                 1       2    2  42.0      0      0   13.0000       3.0   \n",
       "867                 1       2    2  27.0      1      0   13.8583       1.0   \n",
       "868                 0       1    1  31.0      0      0   50.4958       3.0   \n",
       "869                 0       3    1   NaN      0      0    9.5000       3.0   \n",
       "870                 1       3    1   4.0      1      1   11.1333       3.0   \n",
       "871                 0       3    1  26.0      0      0    7.8958       3.0   \n",
       "872                 1       1    2  47.0      1      1   52.5542       3.0   \n",
       "873                 0       1    1  33.0      0      0    5.0000       3.0   \n",
       "874                 0       3    1  47.0      0      0    9.0000       3.0   \n",
       "875                 1       2    2  28.0      1      0   24.0000       1.0   \n",
       "876                 1       3    2  15.0      0      0    7.2250       1.0   \n",
       "877                 0       3    1  20.0      0      0    9.8458       3.0   \n",
       "878                 0       3    1  19.0      0      0    7.8958       3.0   \n",
       "879                 0       3    1   NaN      0      0    7.8958       3.0   \n",
       "880                 1       1    2  56.0      0      1   83.1583       1.0   \n",
       "881                 1       2    2  25.0      0      1   26.0000       3.0   \n",
       "882                 0       3    1  33.0      0      0    7.8958       3.0   \n",
       "883                 0       3    2  22.0      0      0   10.5167       3.0   \n",
       "884                 0       2    1  28.0      0      0   10.5000       3.0   \n",
       "885                 0       3    1  25.0      0      0    7.0500       3.0   \n",
       "886                 0       3    2  39.0      0      5   29.1250       2.0   \n",
       "887                 0       2    1  27.0      0      0   13.0000       3.0   \n",
       "888                 1       1    2  19.0      0      0   30.0000       3.0   \n",
       "889                 0       3    2   NaN      1      2   23.4500       3.0   \n",
       "890                 1       1    1  26.0      0      0   30.0000       1.0   \n",
       "891                 0       3    1  32.0      0      0    7.7500       2.0   \n",
       "\n",
       "             Age_Cut  women_1st_2nd_class  \n",
       "PassengerId                                \n",
       "1                2.0                  0.0  \n",
       "2                3.0                  1.0  \n",
       "3                2.0                  0.0  \n",
       "4                3.0                  1.0  \n",
       "5                3.0                  0.0  \n",
       "6                NaN                  0.0  \n",
       "7                5.0                  0.0  \n",
       "8                0.0                  0.0  \n",
       "9                2.0                  0.0  \n",
       "10               1.0                  1.0  \n",
       "11               0.0                  0.0  \n",
       "12               5.0                  1.0  \n",
       "13               2.0                  0.0  \n",
       "14               3.0                  0.0  \n",
       "15               1.0                  0.0  \n",
       "16               5.0                  1.0  \n",
       "17               0.0                  0.0  \n",
       "18               NaN                  0.0  \n",
       "19               3.0                  0.0  \n",
       "20               NaN                  0.0  \n",
       "21               3.0                  0.0  \n",
       "22               3.0                  0.0  \n",
       "23               1.0                  0.0  \n",
       "24               2.0                  0.0  \n",
       "25               0.0                  0.0  \n",
       "26               3.0                  0.0  \n",
       "27               NaN                  0.0  \n",
       "28               1.0                  0.0  \n",
       "29               NaN                  0.0  \n",
       "30               NaN                  0.0  \n",
       "...              ...                  ...  \n",
       "862              2.0                  0.0  \n",
       "863              4.0                  1.0  \n",
       "864              NaN                  0.0  \n",
       "865              2.0                  0.0  \n",
       "866              4.0                  1.0  \n",
       "867              2.0                  1.0  \n",
       "868              3.0                  0.0  \n",
       "869              NaN                  0.0  \n",
       "870              0.0                  0.0  \n",
       "871              2.0                  0.0  \n",
       "872              4.0                  1.0  \n",
       "873              3.0                  0.0  \n",
       "874              4.0                  0.0  \n",
       "875              2.0                  1.0  \n",
       "876              1.0                  0.0  \n",
       "877              2.0                  0.0  \n",
       "878              1.0                  0.0  \n",
       "879              NaN                  0.0  \n",
       "880              5.0                  1.0  \n",
       "881              2.0                  1.0  \n",
       "882              3.0                  0.0  \n",
       "883              2.0                  0.0  \n",
       "884              2.0                  0.0  \n",
       "885              2.0                  0.0  \n",
       "886              3.0                  0.0  \n",
       "887              2.0                  0.0  \n",
       "888              1.0                  1.0  \n",
       "889              NaN                  0.0  \n",
       "890              2.0                  0.0  \n",
       "891              3.0                  0.0  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing For Maching Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 일단 Null값들 처리해야됨. \n",
    "null이 있었던 column은 총 2개 -> Age, Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_train_data = train_data_with_new_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 10 columns):\n",
      "Survived               891 non-null int64\n",
      "Pclass                 891 non-null int64\n",
      "Sex                    891 non-null int64\n",
      "Age                    714 non-null float64\n",
      "SibSp                  891 non-null int64\n",
      "Parch                  891 non-null int64\n",
      "Fare                   891 non-null float64\n",
      "Embarked               889 non-null float64\n",
      "Age_Cut                713 non-null float64\n",
      "women_1st_2nd_class    891 non-null float64\n",
      "dtypes: float64(5), int64(5)\n",
      "memory usage: 76.6 KB\n"
     ]
    }
   ],
   "source": [
    "pre_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd27b93e48>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSYWw0CWpEP8Hq/bCllhlvlUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd27594978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_train_data['Age'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd27905ac8>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1LjLHpJatz/A9pO2wPfjdn1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd285f5e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_train_data['Embarked'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age에 null이 좀 많고, <br>\n",
    "embarked에는 2개<br>\n",
    "embarked row는 어쩔 수 없이 날려야 될 것 같고, <br>\n",
    "**Age는 Right-Skewed -> Median으로 채우자**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_train_data = pre_train_data.dropna(subset=[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age_median = float(pre_train_data['Age'].median())\n",
    "pre_train_data['Age'].fillna(age_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Index.drop of Int64Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "            ...\n",
       "            882, 883, 884, 885, 886, 887, 888, 889, 890, 891],\n",
       "           dtype='int64', name='PassengerId', length=889)>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_train_data.index.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_train_data = pre_train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = pd.DataFrame(pre_train_data['Survived'])\n",
    "train_x = pre_train_data.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding<br>\n",
    "Y - Survived <br>\n",
    "X - pclasss, sex, embarked를 one-hot encoding 해야 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pclass_encoded = pd.get_dummies(train_x['Pclass'])\n",
    "sex_encoded = pd.get_dummies(train_x['Sex'])\n",
    "embarked_encoded = pd.get_dummies(train_x['Embarked'])\n",
    "y_encoded = pd.get_dummies(train_y['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x_encoded = train_x.drop(['Pclass', 'Embarked', 'Sex'],axis=1)\n",
    "train_y_encoded = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_encoded = pd.concat([train_x_encoded ,pclass_encoded, sex_encoded, embarked_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  SibSp  Parch      Fare  Age_Cut  women_1st_2nd_class  1  2  3  1  \\\n",
      "0    22.0      1      0    7.2500      2.0                  0.0  0  0  1  1   \n",
      "1    38.0      1      0   71.2833      3.0                  1.0  1  0  0  0   \n",
      "2    26.0      0      0    7.9250      2.0                  0.0  0  0  1  0   \n",
      "3    35.0      1      0   53.1000      3.0                  1.0  1  0  0  0   \n",
      "4    35.0      0      0    8.0500      3.0                  0.0  0  0  1  1   \n",
      "5    28.0      0      0    8.4583      NaN                  0.0  0  0  1  1   \n",
      "6    54.0      0      0   51.8625      5.0                  0.0  1  0  0  1   \n",
      "7     2.0      3      1   21.0750      0.0                  0.0  0  0  1  1   \n",
      "8    27.0      0      2   11.1333      2.0                  0.0  0  0  1  0   \n",
      "9    14.0      1      0   30.0708      1.0                  1.0  0  1  0  0   \n",
      "10    4.0      1      1   16.7000      0.0                  0.0  0  0  1  0   \n",
      "11   58.0      0      0   26.5500      5.0                  1.0  1  0  0  0   \n",
      "12   20.0      0      0    8.0500      2.0                  0.0  0  0  1  1   \n",
      "13   39.0      1      5   31.2750      3.0                  0.0  0  0  1  1   \n",
      "14   14.0      0      0    7.8542      1.0                  0.0  0  0  1  0   \n",
      "15   55.0      0      0   16.0000      5.0                  1.0  0  1  0  0   \n",
      "16    2.0      4      1   29.1250      0.0                  0.0  0  0  1  1   \n",
      "17   28.0      0      0   13.0000      NaN                  0.0  0  1  0  1   \n",
      "18   31.0      1      0   18.0000      3.0                  0.0  0  0  1  0   \n",
      "19   28.0      0      0    7.2250      NaN                  0.0  0  0  1  0   \n",
      "20   35.0      0      0   26.0000      3.0                  0.0  0  1  0  1   \n",
      "21   34.0      0      0   13.0000      3.0                  0.0  0  1  0  1   \n",
      "22   15.0      0      0    8.0292      1.0                  0.0  0  0  1  0   \n",
      "23   28.0      0      0   35.5000      2.0                  0.0  1  0  0  1   \n",
      "24    8.0      3      1   21.0750      0.0                  0.0  0  0  1  0   \n",
      "25   38.0      1      5   31.3875      3.0                  0.0  0  0  1  0   \n",
      "26   28.0      0      0    7.2250      NaN                  0.0  0  0  1  1   \n",
      "27   19.0      3      2  263.0000      1.0                  0.0  1  0  0  1   \n",
      "28   28.0      0      0    7.8792      NaN                  0.0  0  0  1  0   \n",
      "29   28.0      0      0    7.8958      NaN                  0.0  0  0  1  1   \n",
      "..    ...    ...    ...       ...      ...                  ... .. .. .. ..   \n",
      "859  21.0      1      0   11.5000      2.0                  0.0  0  1  0  1   \n",
      "860  48.0      0      0   25.9292      4.0                  1.0  1  0  0  0   \n",
      "861  28.0      8      2   69.5500      NaN                  0.0  0  0  1  0   \n",
      "862  24.0      0      0   13.0000      2.0                  0.0  0  1  0  1   \n",
      "863  42.0      0      0   13.0000      4.0                  1.0  0  1  0  0   \n",
      "864  27.0      1      0   13.8583      2.0                  1.0  0  1  0  0   \n",
      "865  31.0      0      0   50.4958      3.0                  0.0  1  0  0  1   \n",
      "866  28.0      0      0    9.5000      NaN                  0.0  0  0  1  1   \n",
      "867   4.0      1      1   11.1333      0.0                  0.0  0  0  1  1   \n",
      "868  26.0      0      0    7.8958      2.0                  0.0  0  0  1  1   \n",
      "869  47.0      1      1   52.5542      4.0                  1.0  1  0  0  0   \n",
      "870  33.0      0      0    5.0000      3.0                  0.0  1  0  0  1   \n",
      "871  47.0      0      0    9.0000      4.0                  0.0  0  0  1  1   \n",
      "872  28.0      1      0   24.0000      2.0                  1.0  0  1  0  0   \n",
      "873  15.0      0      0    7.2250      1.0                  0.0  0  0  1  0   \n",
      "874  20.0      0      0    9.8458      2.0                  0.0  0  0  1  1   \n",
      "875  19.0      0      0    7.8958      1.0                  0.0  0  0  1  1   \n",
      "876  28.0      0      0    7.8958      NaN                  0.0  0  0  1  1   \n",
      "877  56.0      0      1   83.1583      5.0                  1.0  1  0  0  0   \n",
      "878  25.0      0      1   26.0000      2.0                  1.0  0  1  0  0   \n",
      "879  33.0      0      0    7.8958      3.0                  0.0  0  0  1  1   \n",
      "880  22.0      0      0   10.5167      2.0                  0.0  0  0  1  0   \n",
      "881  28.0      0      0   10.5000      2.0                  0.0  0  1  0  1   \n",
      "882  25.0      0      0    7.0500      2.0                  0.0  0  0  1  1   \n",
      "883  39.0      0      5   29.1250      3.0                  0.0  0  0  1  0   \n",
      "884  27.0      0      0   13.0000      2.0                  0.0  0  1  0  1   \n",
      "885  19.0      0      0   30.0000      1.0                  1.0  1  0  0  0   \n",
      "886  28.0      1      2   23.4500      NaN                  0.0  0  0  1  0   \n",
      "887  26.0      0      0   30.0000      2.0                  0.0  1  0  0  1   \n",
      "888  32.0      0      0    7.7500      3.0                  0.0  0  0  1  1   \n",
      "\n",
      "     2  1.0  2.0  3.0  \n",
      "0    0    0    0    1  \n",
      "1    1    1    0    0  \n",
      "2    1    0    0    1  \n",
      "3    1    0    0    1  \n",
      "4    0    0    0    1  \n",
      "5    0    0    1    0  \n",
      "6    0    0    0    1  \n",
      "7    0    0    0    1  \n",
      "8    1    0    0    1  \n",
      "9    1    1    0    0  \n",
      "10   1    0    0    1  \n",
      "11   1    0    0    1  \n",
      "12   0    0    0    1  \n",
      "13   0    0    0    1  \n",
      "14   1    0    0    1  \n",
      "15   1    0    0    1  \n",
      "16   0    0    1    0  \n",
      "17   0    0    0    1  \n",
      "18   1    0    0    1  \n",
      "19   1    1    0    0  \n",
      "20   0    0    0    1  \n",
      "21   0    0    0    1  \n",
      "22   1    0    1    0  \n",
      "23   0    0    0    1  \n",
      "24   1    0    0    1  \n",
      "25   1    0    0    1  \n",
      "26   0    1    0    0  \n",
      "27   0    0    0    1  \n",
      "28   1    0    1    0  \n",
      "29   0    0    0    1  \n",
      "..  ..  ...  ...  ...  \n",
      "859  0    0    0    1  \n",
      "860  1    0    0    1  \n",
      "861  1    0    0    1  \n",
      "862  0    0    0    1  \n",
      "863  1    0    0    1  \n",
      "864  1    1    0    0  \n",
      "865  0    0    0    1  \n",
      "866  0    0    0    1  \n",
      "867  0    0    0    1  \n",
      "868  0    0    0    1  \n",
      "869  1    0    0    1  \n",
      "870  0    0    0    1  \n",
      "871  0    0    0    1  \n",
      "872  1    1    0    0  \n",
      "873  1    1    0    0  \n",
      "874  0    0    0    1  \n",
      "875  0    0    0    1  \n",
      "876  0    0    0    1  \n",
      "877  1    1    0    0  \n",
      "878  1    0    0    1  \n",
      "879  0    0    0    1  \n",
      "880  1    0    0    1  \n",
      "881  0    0    0    1  \n",
      "882  0    0    0    1  \n",
      "883  1    0    1    0  \n",
      "884  0    0    0    1  \n",
      "885  1    0    0    1  \n",
      "886  1    0    0    1  \n",
      "887  0    1    0    0  \n",
      "888  0    0    1    0  \n",
      "\n",
      "[889 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_x_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age_Cut은 Nan값을 채우기 전에 만든 것임으로<br>\n",
    "Age가 NaN이였던 Row의 Age_Cut은 아직도 NaN임.<br>\n",
    "그 친구들 채워야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_with_ages = train_x_encoded.copy()\n",
    "train_x_encoded['Age_Cut'] = pd.cut(train_data_with_ages['Age'], labels=labels,\n",
    "bins=bins, include_lowest = True)\n",
    "\n",
    "train_x_encoded['Age_Cut'] = train_x_encoded['Age_Cut'].astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age_Cut</th>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch  Fare  Age_Cut  women_1st_2nd_class  1  2  3  1  2  \\\n",
       "629  80.0    0.0    0.0  30.0      NaN                  0.0  1  0  0  1  0   \n",
       "\n",
       "     1.0  2.0  3.0  \n",
       "629    0    0    1  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_encoded[train_x_encoded['Age_Cut'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_encoded[train_x_encoded['Age_Cut'].isnull()]=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age_Cut</th>\n",
       "      <th>women_1st_2nd_class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Age, SibSp, Parch, Fare, Age_Cut, women_1st_2nd_class, 1, 2, 3, 1, 2, 1.0, 2.0, 3.0]\n",
       "Index: []"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_encoded[train_x_encoded['Age_Cut'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 889 entries, 0 to 888\n",
      "Data columns (total 14 columns):\n",
      "Age                    889 non-null float64\n",
      "SibSp                  889 non-null float64\n",
      "Parch                  889 non-null float64\n",
      "Fare                   889 non-null float64\n",
      "Age_Cut                889 non-null float64\n",
      "women_1st_2nd_class    889 non-null float64\n",
      "1                      889 non-null uint8\n",
      "2                      889 non-null uint8\n",
      "3                      889 non-null uint8\n",
      "1                      889 non-null uint8\n",
      "2                      889 non-null uint8\n",
      "1.0                    889 non-null uint8\n",
      "2.0                    889 non-null uint8\n",
      "3.0                    889 non-null uint8\n",
      "dtypes: float64(6), uint8(8)\n",
      "memory usage: 48.7 KB\n"
     ]
    }
   ],
   "source": [
    "train_x_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_encoded['SibSp'] = train_x_encoded['SibSp'].astype(float) \n",
    "train_x_encoded['Parch'] = train_x_encoded['Parch'].astype(float) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "Age, Fare, SibSp, Parch, Age_Cut을 Scaling 할 것<br>\n",
    "stdscaler or MinMax Scaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "before_scaler = train_x_encoded[['Age', 'Fare', 'SibSp', 'Parch', 'Age_Cut']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_scaler = pd.DataFrame(stdscaler.fit_transform(before_scaler),\n",
    "             columns=before_scaler.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_x= train_x_encoded.drop(['Age', 'Fare', 'SibSp', 'Parch'],\n",
    "                                                 axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_scaled = pd.concat([after_scaler, drop_x], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 15)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train x : train_x_scaled<br>\n",
    "train y : train_y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_x_scaled.values\n",
    "y = train_y.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "**Feedback**<br>\n",
    "***Ground Truth***<br>\n",
    "Accuracy를 구하려면 최소 하나로 몰빵 예측했을때 보다는 높아야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38245219347581555\n"
     ]
    }
   ],
   "source": [
    "print(sum(y==1)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6175478065241845\n"
     ]
    }
   ],
   "source": [
    "print(sum(y==0)/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다 살았다고 예측하면 38% 맞고, 다 죽었다고 예측하면 61% 맞음.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logitstic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79775281 0.79775281 0.76404494 0.83146067 0.83146067 0.79775281\n",
      " 0.82022472 0.79775281 0.84269663 0.82954545]\n",
      "mean:  0.811044433094995\n",
      "Standard Deviation:  0.022754546448635508\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(log_reg, X, y, cv=10)\n",
    "print(scores)\n",
    "print(\"mean: \", np.mean(scores))\n",
    "print(\"Standard Deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver_list = ['lbfgs','sag', 'saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver lbfgs  scores\n",
      "mean:  0.44762533561236173\n",
      "Standard Deviation:  0.03035029033192375\n",
      "solver sag  scores\n",
      "mean:  0.44762533561236173\n",
      "Standard Deviation:  0.03035029033192375\n",
      "solver saga  scores\n",
      "mean:  0.44762533561236173\n",
      "Standard Deviation:  0.03035029033192375\n"
     ]
    }
   ],
   "source": [
    "for i in solver_list:\n",
    "    softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=i, C=10)\n",
    "    softmax_reg.fit(X, y)\n",
    "    scores = cross_val_score(softmax_reg, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    print('solver', i, ' scores')\n",
    "    print(\"mean: \", np.mean(rmse_scores))\n",
    "    print(\"Standard Deviation: \", np.std(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best C value is 421\n",
      "The rmse of C= 421 is  0.5707476196902691\n"
     ]
    }
   ],
   "source": [
    "c_dict = {}\n",
    "for i in range(1, 500, 20):\n",
    "    linear_svc =LinearSVC(C =i, loss=\"hinge\")\n",
    "    linear_svc.fit(X, y)\n",
    "    scores = cross_val_score(linear_svc, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    c_dict[i]=np.mean(rmse_scores)\n",
    "    \n",
    "    \n",
    "for key, value in c_dict.items():\n",
    "    if value == max(c_dict.values()):\n",
    "        print(\"The Best C value is\", key)\n",
    "        print(\"The rmse of C=\", key, \"is \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Non-Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_dict ={}\n",
    "\n",
    "for i in list([2, 3, 4]):\n",
    "    poly_features = PolynomialFeatures(degree=i)\n",
    "    x_poly = poly_features.fit_transform(X)\n",
    "    \n",
    "    for j in range(1, 500, 20):\n",
    "        linear_svc = LinearSVC(C =j, loss=\"hinge\")\n",
    "        linear_svc.fit(x_poly, y)\n",
    "        scores = cross_val_score(linear_svc, x_poly, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        p_dict[i, j]=np.mean(rmse_scores)\n",
    "        #i= degree, j=C\n",
    "                \n",
    "    \n",
    "for key, value in p_dict.items():\n",
    "    if value == max(p_dict.values()):\n",
    "        print(\"The Best C value is\", key[1])\n",
    "        print(\"The Best Degree value is\", key[0])\n",
    "        print(\"The rmse is \", value)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degree_param = [x for x in range(2, 5)]\n",
    "coef0_param = [x for x in range(1, 100, 10)]\n",
    "C_param = [x for x in range(1, 500, 50)]\n",
    "param_grid = [\n",
    "    {'degree': degree_param, 'coef0': coef0_param, 'C': C_param }\n",
    "]\n",
    "#degree, coef, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel=\"poly\")\n",
    "grid_search = GridSearchCV(svm_clf, param_grid, cv=5,\n",
    "                           scoring=\"neg_mean_squared_error\",\n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X, y)\n",
    "#이거 왜 이렇게 오래 걸리지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5580047101940405\n"
     ]
    }
   ],
   "source": [
    "svm_clf  = SVC(kernel=\"poly\", degree=3, coef0=5, C=10)\n",
    "scores = cross_val_score(linear_svc, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가우시안 BRF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5576648819896322\n"
     ]
    }
   ],
   "source": [
    "svm_clf  = SVC(kernel=\"rbf\", gamma=5, coef0=5, C=0.001)\n",
    "scores = cross_val_score(linear_svc, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 9/24 Mon AM 1 : 30 ~  2 : 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeClassifier(min_samples_leaf=1, max_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.48656835176636326\n",
      "Standard Deviation:  0.024454477921571842\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tree_reg, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(\"mean: \", np.mean(rmse_scores))\n",
    "print(\"Standard Deviation: \", np.std(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_reg = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43704832 0.42399915 0.49718308 0.33520076 0.33520076 0.42399915\n",
      " 0.44971901 0.47404546 0.36719404 0.42640143]\n",
      "mean:  0.41699911716208843\n",
      "Standard Deviation:  0.052158611561197644\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(forest_reg, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)\n",
    "print(\"mean: \", np.mean(rmse_scores))\n",
    "print(\"Standard Deviation: \", np.std(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf_hard = SVC()\n",
    "svm_clf_soft = SVC(probability=True)\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "        estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf_hard)],\n",
    "        voting= 'hard')\n",
    "\n",
    "voting_clf_soft=VotingClassifier(\n",
    "        estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf_soft)],\n",
    "        voting= 'soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 1)\n",
      "(889,)\n"
     ]
    }
   ],
   "source": [
    "y1=y.reshape((-1, 1))\n",
    "print(y1.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43704832 0.41053541 0.47404546 0.36719404 0.39661489 0.44971901\n",
      " 0.39661489 0.43704832 0.39661489 0.41286141]\n",
      "mean:  0.41782966526516796\n",
      "Standard Deviation:  0.029846133116151776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sanghyuk/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(voting_clf_soft, X, y1, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)\n",
    "print(\"mean: \", np.mean(rmse_scores))\n",
    "print(\"Standard Deviation: \", np.std(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "        LogisticRegression(), n_estimators = 50,\n",
    "        max_samples=50, bootstrap=True, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=50, n_estimators=50, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47404546 0.46204236 0.48575205 0.39661489 0.47404546 0.47404546\n",
      " 0.46204236 0.47404546 0.39661489 0.45226702]\n",
      "mean:  0.4551515428989859\n",
      "Standard Deviation:  0.030529786920650517\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(bag_clf, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)\n",
    "print(\"mean: \", np.mean(rmse_scores))\n",
    "print(\"Standard Deviation: \", np.std(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "        LogisticRegression(), n_estimators = 50,\n",
    "        max_samples=50, bootstrap=False, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44971901 0.46204236 0.47404546 0.39661489 0.44971901 0.46204236\n",
      " 0.46204236 0.48575205 0.39661489 0.46466019]\n",
      "mean:  0.45032526020721153\n",
      "Standard Deviation:  0.028645087193594935\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(bag_clf, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)\n",
    "print(\"mean: \", np.mean(rmse_scores))\n",
    "print(\"Standard Deviation: \", np.std(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(), n_estimators=200,\n",
    "        algorithm=\"SAMME.R\", learning_rate=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55079106 0.49718308 0.50835712 0.41053541 0.35156152 0.48575205\n",
      " 0.42399915 0.50835712 0.41053541 0.47673129]\n",
      "mean:  0.46238032316166633\n",
      "Standard Deviation:  0.057565023687095485\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ada_clf, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)\n",
    "print(\"mean: \", np.mean(rmse_scores))\n",
    "print(\"Standard Deviation: \", np.std(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "        LogisticRegression(), n_estimators=200,\n",
    "        algorithm=\"SAMME.R\", learning_rate=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44971901 0.46204236 0.48575205 0.39661489 0.41053541 0.44971901\n",
      " 0.43704832 0.48575205 0.38218767 0.45226702]\n",
      "mean:  0.44116378083588986\n",
      "Standard Deviation:  0.033316104357096483\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ada_clf, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores)\n",
    "print(\"mean: \", np.mean(rmse_scores))\n",
    "print(\"Standard Deviation: \", np.std(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
